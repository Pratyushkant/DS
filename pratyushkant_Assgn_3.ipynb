{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rk-9UZY_xe2"
   },
   "source": [
    "# UMC 301: Applied Data Science and Artificial Intelligence\n",
    "## Assignment 3\n",
    "\n",
    "### Submission instructions:\n",
    "\n",
    "1.   The assignment is to be submitted in ONE single notebook.\n",
    "2.   Submit the .ipynb file with all cells open and the pdf for part 2 through Teams Assignment.\n",
    "3. If your IISc email ID is < username > @iisc.ac.in, then name the file < username >_Assgn_3. E.g. jonathan_Assgn_3 for email ID jonathan@iisc.ac.in.\n",
    "4. Before submission, execute the ’Restart session and run all’ option from the Runtime/Kernel tab. Verify that there are no errors and that you are getting the output you expect.\n",
    "5. Use the dataset: https://github.com/taivop/joke-dataset\n",
    "6. The assignment is divided into two questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropping data\n",
    "- num_epochs ine xperiment tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bma59Wpv_xe3"
   },
   "source": [
    "## Question 1\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Load the dataset, create train, validation and test splits. Preprocess the dataset as required to train a decoder model. (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:01.956572Z",
     "iopub.status.busy": "2024-10-31T10:53:01.956258Z",
     "iopub.status.idle": "2024-10-31T10:53:03.036030Z",
     "shell.execute_reply": "2024-10-31T10:53:03.034736Z",
     "shell.execute_reply.started": "2024-10-31T10:53:01.956540Z"
    },
    "id": "H88Xkndfoe3S",
    "outputId": "a75fbbc7-a449-47fe-e1c8-4dbd584fbfa0",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'joke-dataset'...\n",
      "remote: Enumerating objects: 44, done.\u001b[K\n",
      "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 44 (delta 12), reused 10 (delta 10), pack-reused 30 (from 1)\u001b[K\n",
      "Receiving objects: 100% (44/44), 32.38 MiB | 14.11 MiB/s, done.\n",
      "Resolving deltas: 100% (21/21), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/taivop/joke-dataset # clone the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:14.712366Z",
     "iopub.status.busy": "2024-10-31T10:53:14.712006Z",
     "iopub.status.idle": "2024-10-31T10:53:14.722993Z",
     "shell.execute_reply": "2024-10-31T10:53:14.722211Z",
     "shell.execute_reply.started": "2024-10-31T10:53:14.712328Z"
    },
    "id": "1p_RwECZoe3T",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratyushkant/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import shutil\n",
    "import warnings\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.auto import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional, Union\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from typing import Dict, Any, List\n",
    "from contextlib import nullcontext\n",
    "from fpdf import FPDF\n",
    "import sys\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "import gc\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzqwOYWgoe3U"
   },
   "source": [
    "Extract the ASCII characters (a to z, A to Z, 0 to 9) from the body category of the JSON files (stupidstuff.json, wocka.json) and from both title and body for reddit_jokes.json and save it as a csv file in another directory 'output_csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:14.724615Z",
     "iopub.status.busy": "2024-10-31T10:53:14.724300Z",
     "iopub.status.idle": "2024-10-31T10:53:20.684571Z",
     "shell.execute_reply": "2024-10-31T10:53:20.683566Z",
     "shell.execute_reply.started": "2024-10-31T10:53:14.724583Z"
    },
    "id": "bq2SwQJFoe3U",
    "outputId": "822a35dc-9dc8-4d18-c54a-4f1df5564006",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files have been successfully generated.\n"
     ]
    }
   ],
   "source": [
    "# Function to extract ASCII characters\n",
    "def extract_ascii(text):\n",
    "    # Use regex to extract only alphanumeric characters (a-z, A-Z, 0-9) and spaces\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "# Function to write extracted text to CSV\n",
    "def write_to_csv(data, file_path, headers):\n",
    "    with open(file_path, mode='w', newline='', encoding='utf-8') as file: # Open the file in write mode\n",
    "        writer = csv.writer(file) # Create a CSV writer\n",
    "        writer.writerow(headers) # Write the headers\n",
    "        for row in data: # Iterate over the data\n",
    "            writer.writerow(row) # Write the row\n",
    "\n",
    "# Process the stupidstuff.json and wocka.json files\n",
    "def process_single_body_json(file_path, output_csv):\n",
    "    extracted_data = [] # Initialize an empty list to store the extracted data\n",
    "\n",
    "    # Load JSON file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        jokes = json.load(file) # Load the JSON file\n",
    "\n",
    "    # Extract ASCII from the 'body' field of each joke\n",
    "    for joke in jokes:  # Iterate over the jokes\n",
    "        if 'body' in joke: # Check if the joke has a 'body' field\n",
    "            clean_body = extract_ascii(joke['body']) # Extract ASCII characters from the 'body' field\n",
    "            extracted_data.append([clean_body]) # Append the extracted text to the list\n",
    "\n",
    "    # Write to CSV\n",
    "    write_to_csv(extracted_data, output_csv, headers=['body'])\n",
    "\n",
    "# Process the reddit_jokes.json file\n",
    "def process_reddit_jokes_json(file_path, output_csv):\n",
    "    extracted_data = [] # Initialize an empty list to store the extracted data\n",
    "\n",
    "    # Load JSON file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        jokes = json.load(file) # Load the JSON file\n",
    "\n",
    "    # Extract ASCII from both 'title' and 'body', concatenate them\n",
    "    for joke in jokes: # Iterate over the jokes\n",
    "        if 'title' in joke and 'body' in joke: # Check if the joke has both 'title' and 'body' fields\n",
    "            clean_title = extract_ascii(joke['title']) # Extract ASCII characters from the 'title' field\n",
    "            clean_body = extract_ascii(joke['body']) # Extract ASCII characters from the 'body' field\n",
    "            concatenated = clean_title + \" \" + clean_body # Concatenate the title and body\n",
    "            extracted_data.append([concatenated]) # Append the extracted text to the list\n",
    "\n",
    "    # Write to CSV\n",
    "    write_to_csv(extracted_data, output_csv, headers=['body']) # Write the extracted data to a CSV file\n",
    "\n",
    "# Paths for input and output files\n",
    "input_folder = 'joke-dataset' # Folder containing the JSON files\n",
    "output_folder = 'output_csv' # Folder to store the CSV files\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True) # Create the output folder if it does not exist\n",
    "\n",
    "# Process stupidstuff.json\n",
    "process_single_body_json(os.path.join(input_folder, 'stupidstuff.json'), os.path.join(output_folder, 'stupidstuff.csv')) # Process the stupidstuff.json file\n",
    "\n",
    "# Process wocka.json\n",
    "process_single_body_json(os.path.join(input_folder, 'wocka.json'), os.path.join(output_folder, 'wocka.csv')) # Process the wocka.json file\n",
    "\n",
    "# Process reddit_jokes.json\n",
    "process_reddit_jokes_json(os.path.join(input_folder, 'reddit_jokes.json'), os.path.join(output_folder, 'reddit_jokes.csv')) # Process the reddit_jokes.json file\n",
    "\n",
    "print(\"CSV files have been successfully generated.\") # Print a message to indicate that the CSV files have been generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:20.686634Z",
     "iopub.status.busy": "2024-10-31T10:53:20.686232Z",
     "iopub.status.idle": "2024-10-31T10:53:21.283428Z",
     "shell.execute_reply": "2024-10-31T10:53:21.282491Z",
     "shell.execute_reply.started": "2024-10-31T10:53:20.686588Z"
    },
    "id": "6O5g6St7oe3V",
    "outputId": "23346bea-7a92-4f27-d50c-c5565afaf2aa",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stupidstuff.csv columns:\n",
      "Index(['body'], dtype='object')\n",
      "\n",
      "wocka.csv columns:\n",
      "Index(['body'], dtype='object')\n",
      "\n",
      "reddit_jokes.csv columns:\n",
      "Index(['body'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Report all the columns for each CSV file\n",
    "\n",
    "# Load the CSV files\n",
    "stupidstuff_df = pd.read_csv(os.path.join(output_folder, 'stupidstuff.csv'))\n",
    "wocka_df = pd.read_csv(os.path.join(output_folder, 'wocka.csv'))\n",
    "reddit_jokes_df = pd.read_csv(os.path.join(output_folder, 'reddit_jokes.csv'))\n",
    "\n",
    "# Display the columns for each CSV file\n",
    "print(\"stupidstuff.csv columns:\")\n",
    "print(stupidstuff_df.columns)\n",
    "print(\"\\nwocka.csv columns:\")\n",
    "print(wocka_df.columns)\n",
    "print(\"\\nreddit_jokes.csv columns:\")\n",
    "print(reddit_jokes_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxwYIOgroe3V"
   },
   "source": [
    "Merge all the csv files as joke.csv in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:21.285644Z",
     "iopub.status.busy": "2024-10-31T10:53:21.284899Z",
     "iopub.status.idle": "2024-10-31T10:53:23.599565Z",
     "shell.execute_reply": "2024-10-31T10:53:23.598311Z",
     "shell.execute_reply.started": "2024-10-31T10:53:21.285595Z"
    },
    "id": "wnhC6GsBoe3V",
    "outputId": "800d528e-aabf-4172-db8a-9ebc24311398",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_jokes.csv has been successfully generated.\n"
     ]
    }
   ],
   "source": [
    "# Merge the three dataframes into a single dataframe\n",
    "# named all_jokes_df and save it as a CSV file\n",
    "\n",
    "all_jokes_df = pd.concat([stupidstuff_df, wocka_df, reddit_jokes_df], ignore_index=True)\n",
    "all_jokes_df.to_csv(os.path.join('all_jokes.csv'), index=False)\n",
    "\n",
    "print(\"all_jokes.csv has been successfully generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:23.601257Z",
     "iopub.status.busy": "2024-10-31T10:53:23.600933Z",
     "iopub.status.idle": "2024-10-31T10:53:23.665264Z",
     "shell.execute_reply": "2024-10-31T10:53:23.664091Z",
     "shell.execute_reply.started": "2024-10-31T10:53:23.601224Z"
    },
    "id": "Pn1hb-tBoe3V",
    "outputId": "512ac823-79aa-4cc0-82db-2ea3d080d2e4",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of all_jokes_df matches the sum of lengths of the three dataframes.\n",
      "\n",
      "all_jokes.csv columns:\n",
      "Index(['body'], dtype='object')\n",
      "Number of missing values in all_jokes_df matches the sum of missing values in the three dataframes.\n"
     ]
    }
   ],
   "source": [
    "# Check if length of all_jokes_df is equal to the sum\n",
    "# of lengths of the three dataframes\n",
    "\n",
    "total_length = len(stupidstuff_df) + len(wocka_df) + len(reddit_jokes_df)\n",
    "if len(all_jokes_df) == total_length:\n",
    "    print(\"Length of all_jokes_df matches the sum of lengths of the three dataframes.\")\n",
    "\n",
    "# Display the columns for all_jokes.csv\n",
    "print(\"\\nall_jokes.csv columns:\")\n",
    "print(all_jokes_df.columns)\n",
    "\n",
    "# Check if number of missing values in the 'body' column\n",
    "# of all_jokes_df is equal to the sum of missing values\n",
    "# in the 'body' columns of the three dataframes\n",
    "\n",
    "missing_values = all_jokes_df['body'].isnull().sum()\n",
    "missing_values_stupidstuff = stupidstuff_df['body'].isnull().sum()\n",
    "missing_values_wocka = wocka_df['body'].isnull().sum()\n",
    "missing_values_reddit_jokes = reddit_jokes_df['body'].isnull().sum()\n",
    "\n",
    "if missing_values == missing_values_stupidstuff + missing_values_wocka + missing_values_reddit_jokes:\n",
    "    print(\"Number of missing values in all_jokes_df matches the sum of missing values in the three dataframes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:23.667579Z",
     "iopub.status.busy": "2024-10-31T10:53:23.667016Z",
     "iopub.status.idle": "2024-10-31T10:53:23.727452Z",
     "shell.execute_reply": "2024-10-31T10:53:23.726462Z",
     "shell.execute_reply.started": "2024-10-31T10:53:23.667532Z"
    },
    "id": "Oh8-7DgQoe3V",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Drop all the values with missing 'body' column\n",
    "all_jokes_df.dropna(subset=['body'], inplace=True)\n",
    "\n",
    "# Shuffle the rows of the dataframe\n",
    "all_jokes_df = all_jokes_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYez2fLqoe3W"
   },
   "source": [
    "Clean the dataset:\n",
    "\n",
    "- Remove Special Characters\n",
    "- Lower casing\n",
    "- Remove Extra Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:23.731444Z",
     "iopub.status.busy": "2024-10-31T10:53:23.731087Z",
     "iopub.status.idle": "2024-10-31T10:53:27.398367Z",
     "shell.execute_reply": "2024-10-31T10:53:27.388310Z",
     "shell.execute_reply.started": "2024-10-31T10:53:23.731382Z"
    },
    "id": "QfQlOHUpoe3W",
    "outputId": "4e4802bf-c663-4b18-abd3-bf2ff742e537",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-alphanumeric characters found: {'\\r', '\\u2000', '\\u2028', '\\u3000', '\\xa0', ' ', '\\u2009', '\\x85', '\\u200a', '\\t', '\\n'}\n"
     ]
    }
   ],
   "source": [
    "# Combine all jokes into a single string\n",
    "all_text = ' '.join(all_jokes_df['body'].astype(str))\n",
    "# Find all unique non-alphanumeric characters\n",
    "non_alphanumeric_chars = set(re.findall(r'[^a-zA-Z0-9]', all_text))\n",
    "# Report the non-alphanumeric characters\n",
    "print(\"Non-alphanumeric characters found:\", non_alphanumeric_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:27.400576Z",
     "iopub.status.busy": "2024-10-31T10:53:27.400169Z",
     "iopub.status.idle": "2024-10-31T10:53:27.413481Z",
     "shell.execute_reply": "2024-10-31T10:53:27.412546Z",
     "shell.execute_reply.started": "2024-10-31T10:53:27.400532Z"
    },
    "id": "xryko7oxoe3W",
    "outputId": "b5930ffd-2740-4bcf-d300-0519d377e239",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the best joke that made you LOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was having sex with a female amputee in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Being a bachelor is dangerous I pulled a groin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Everythings racist these days You cant even sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What did Stevie Wonder say when he tried marih...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body\n",
       "0           What is the best joke that made you LOL \n",
       "1  I was having sex with a female amputee in the ...\n",
       "2  Being a bachelor is dangerous I pulled a groin...\n",
       "3  Everythings racist these days You cant even sa...\n",
       "4  What did Stevie Wonder say when he tried marih..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_jokes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:27.415151Z",
     "iopub.status.busy": "2024-10-31T10:53:27.414779Z",
     "iopub.status.idle": "2024-10-31T10:53:30.109028Z",
     "shell.execute_reply": "2024-10-31T10:53:30.108216Z",
     "shell.execute_reply.started": "2024-10-31T10:53:27.415108Z"
    },
    "id": "pP_S2_9boe3W",
    "outputId": "05370651-a87a-4648-9e88-45fb95315a6e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207761/207761 [00:00<00:00, 1715116.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Enable progress bar for the apply function\n",
    "tqdm.pandas()\n",
    "\n",
    "# make everything in body column lowercase and save the csv file\n",
    "all_jokes_df['body'] = all_jokes_df['body'].progress_apply(lambda x: x.lower())\n",
    "all_jokes_df.to_csv(os.path.join('all_jokes.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:30.110506Z",
     "iopub.status.busy": "2024-10-31T10:53:30.110176Z",
     "iopub.status.idle": "2024-10-31T10:53:48.924123Z",
     "shell.execute_reply": "2024-10-31T10:53:48.923113Z",
     "shell.execute_reply.started": "2024-10-31T10:53:30.110472Z"
    },
    "id": "acULSLXRoe3W",
    "outputId": "418bf360-cefb-4a5e-a5c7-d2ccd0c921bf",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207761/207761 [00:03<00:00, 63688.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove the characters '\\u2000', '\\u200a', '\\u2028', '\\xa0', '\\t', '\\x85', '\\u3000', '\\u2009' and '\\n'\n",
    "chars_to_remove = ['\\u2000', '\\u200a', '\\u2028', '\\xa0', '\\t', '\\x85', '\\u3000', '\\u2009', '\\n', '\\r']\n",
    "\n",
    "tqdm.pandas()\n",
    "# Remove the characters by replacing them with a space\n",
    "all_jokes_df['body'] = all_jokes_df['body'].progress_apply(lambda x: ''.join([char if char not in chars_to_remove else ' ' for char in x]))\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "all_jokes_df.to_csv(os.path.join('all_jokes.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:48.925815Z",
     "iopub.status.busy": "2024-10-31T10:53:48.925499Z",
     "iopub.status.idle": "2024-10-31T10:53:56.385305Z",
     "shell.execute_reply": "2024-10-31T10:53:56.384176Z",
     "shell.execute_reply.started": "2024-10-31T10:53:48.925781Z"
    },
    "id": "CpzV-VTIpdhA",
    "outputId": "cefd3752-92b1-46b3-a74f-9329bd67237b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing spaces in jokes: 100%|██████████| 207761/207761 [00:01<00:00, 150453.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed! Data saved to jokes_normalized.csv\n",
      "\n",
      "Sample of normalized texts:\n",
      "0              what is the best joke that made you lol\n",
      "1    i was having sex with a female amputee in the ...\n",
      "2    being a bachelor is dangerous i pulled a groin...\n",
      "3    everythings racist these days you cant even sa...\n",
      "4    what did stevie wonder say when he tried marih...\n",
      "Name: body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Enable progress bar for pandas operations\n",
    "tqdm.pandas(desc=\"Normalizing spaces in jokes\")\n",
    "\n",
    "# Normalize spaces in the body column using regex\n",
    "# This will replace any number of consecutive whitespace characters with a single space\n",
    "all_jokes_df['body'] = all_jokes_df['body'].progress_apply(\n",
    "    lambda x: re.sub(r'\\s+', ' ', str(x)).strip()\n",
    ")\n",
    "\n",
    "# Save the cleaned data\n",
    "all_jokes_df.to_csv('jokes_normalized.csv', index=False)\n",
    "print(\"Completed! Data saved to jokes_normalized.csv\")\n",
    "\n",
    "# Print a sample to verify\n",
    "print(\"\\nSample of normalized texts:\")\n",
    "print(all_jokes_df['body'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:56.386979Z",
     "iopub.status.busy": "2024-10-31T10:53:56.386651Z",
     "iopub.status.idle": "2024-10-31T10:53:56.523028Z",
     "shell.execute_reply": "2024-10-31T10:53:56.522089Z",
     "shell.execute_reply.started": "2024-10-31T10:53:56.386945Z"
    },
    "id": "YISD2Ng_pyoR",
    "outputId": "f74b329f-d360-4c4e-ab70-5666e7c7dd01",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original file backed up as 'all_jokes_backup.csv'\n",
      "Successfully replaced 'all_jokes.csv' with the normalized version\n"
     ]
    }
   ],
   "source": [
    "# Backup the original file\n",
    "if os.path.exists('all_jokes.csv'):\n",
    "    shutil.copy2('all_jokes.csv', 'all_jokes_backup.csv')\n",
    "    print(\"Original file backed up as 'all_jokes_backup.csv'\")\n",
    "\n",
    "# Replace the original file with the normalized version\n",
    "shutil.move('jokes_normalized.csv', 'all_jokes.csv')\n",
    "print(\"Successfully replaced 'all_jokes.csv' with the normalized version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:56.524689Z",
     "iopub.status.busy": "2024-10-31T10:53:56.524307Z",
     "iopub.status.idle": "2024-10-31T10:53:56.530945Z",
     "shell.execute_reply": "2024-10-31T10:53:56.529963Z",
     "shell.execute_reply.started": "2024-10-31T10:53:56.524654Z"
    },
    "id": "QYmQriXQqGa8",
    "outputId": "82d82970-c50a-4aa0-ab89-755efb5c5257",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              what is the best joke that made you lol\n",
      "1    i was having sex with a female amputee in the ...\n",
      "2    being a bachelor is dangerous i pulled a groin...\n",
      "3    everythings racist these days you cant even sa...\n",
      "4    what did stevie wonder say when he tried marih...\n",
      "Name: body, dtype: object\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check a few samples\n",
    "print(all_jokes_df['body'].head())\n",
    "\n",
    "# count spaces in a row to verify\n",
    "print(all_jokes_df['body'].iloc[0].count('  '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:56.532327Z",
     "iopub.status.busy": "2024-10-31T10:53:56.532052Z",
     "iopub.status.idle": "2024-10-31T10:53:57.388202Z",
     "shell.execute_reply": "2024-10-31T10:53:57.387261Z",
     "shell.execute_reply.started": "2024-10-31T10:53:56.532297Z"
    },
    "id": "3amID_cNoe3X",
    "outputId": "c37debf8-710c-4626-d7cb-ee4265571541",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters in the 'body' column: {'5', 'h', 'l', '2', 's', 't', 'r', 'g', 'f', 'v', '4', 'o', 'z', 'p', 'k', 'i', '8', '1', 'e', ' ', 'b', 'd', '7', 'y', 'c', 'a', 'm', 'w', 'j', 'x', '3', 'q', '9', '0', 'n', '6', 'u'}\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "# Find all the unique characters in the 'body' column\n",
    "\n",
    "all_text = ' '.join(all_jokes_df['body'].astype(str))\n",
    "unique_chars = set(all_text)\n",
    "print(\"Unique characters in the 'body' column:\", unique_chars)\n",
    "print(len(unique_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:57.389932Z",
     "iopub.status.busy": "2024-10-31T10:53:57.389539Z",
     "iopub.status.idle": "2024-10-31T10:53:57.429007Z",
     "shell.execute_reply": "2024-10-31T10:53:57.428085Z",
     "shell.execute_reply.started": "2024-10-31T10:53:57.389888Z"
    },
    "id": "zHhIM8oeoe3X",
    "outputId": "c0725364-8360-4923-dd78-d4720f658d9a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207761\n",
      "134348\n"
     ]
    }
   ],
   "source": [
    "# Make a list of the body column\n",
    "\n",
    "random.seed(40)\n",
    "jokes_list = all_jokes_df['body'].tolist()\n",
    "print(len(jokes_list))\n",
    "\n",
    "# Remove any empty strings and strings with length more than 128\n",
    "jokes_list = [joke for joke in jokes_list if len(joke) <= 128]\n",
    "print(len(jokes_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ive spent all day trying to convince people on reddit im french i give up',\n",
       " 'time for a police based knock knock joke pew pew pew its the police open the door',\n",
       " 'a duck walks into a bar animal control is promptly called and the duck is released in a nearby park',\n",
       " 'my dentist offered to give me dentures for only a dollar it sounded like a good deal at the time but now i have buck teeth',\n",
       " 'i kidnapped this girl last night and she yelled please i dont want to die a virgin if that isnt consent i dont know what is']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a fixed seed to ensure reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Shuffle the jokes list and get the first 5 jokes\n",
    "random.shuffle(jokes_list)\n",
    "jokes_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:53:57.430719Z",
     "iopub.status.busy": "2024-10-31T10:53:57.430301Z",
     "iopub.status.idle": "2024-10-31T10:54:00.455234Z",
     "shell.execute_reply": "2024-10-31T10:54:00.454258Z",
     "shell.execute_reply.started": "2024-10-31T10:53:57.430675Z"
    },
    "id": "jH01TM02FJxG",
    "outputId": "21d86c69-dc21-4a4b-f091-d6980ba0d23b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 53735\n"
     ]
    }
   ],
   "source": [
    "def count_unique_words(sentences):\n",
    "    # Split each sentence into words and make lowercase\n",
    "    all_words = [word.lower() for sentence in sentences for word in sentence.split()]\n",
    "    # Convert to set to get unique words\n",
    "    unique_words = set(all_words)\n",
    "    return len(unique_words)\n",
    "\n",
    "num_unique = count_unique_words(jokes_list)\n",
    "print(f\"Number of unique words: {num_unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165,
     "referenced_widgets": [
      "7431529224344ed5af4a83b4f2c5cdf4",
      "8fc762e24bbd4e2d89d69ec0c0b3a2fd",
      "3859171b6908414a99de4e34c60a8390",
      "3ef8da5e1f934b2ab3f7664a9bf34414",
      "d1bfec2ab87f48a9b9a310421a9cab42",
      "6abbf7a521d24e9193dd693406bf1a0c",
      "e7fdb4efac7c40efac734613f100297a",
      "6354a01e4cd64bd98187dd40b52fbbf9",
      "f50582ae895b47ba929227b318c17aac",
      "91453694c0d843b8896220431ad302ed",
      "f4d4f4b2b65f41239237d8598befcf8b",
      "97cf479f25b74af7a3c30d31538113ad",
      "c7ea1b96cd7b45459f8eb32d1b4600c9",
      "62cb9149543e4bd88b55ddd4403cc669",
      "09ead9e124fe447eb0224f45bbdb8fd9",
      "6f4357cd4fab4658a430e3ebec9ce75a",
      "086e2f292b924444b043e07665c3cf8a",
      "5d3a4e62ba7f4e2bbfdc4cf0710ed047",
      "cb08227717624154b18a6711462d5f6f",
      "33cc70bcdc024c6ca27d55c7e449ccfd",
      "cf01b7033a8e4183877e36fd336520cd",
      "660f718dc4e74ac69e05f6894053d633",
      "c8620d3d2a6d48b0a06a91b4a7289ccf",
      "b2e5ced552424286a48c46f831181568",
      "ee6e93b459b44363beffa86855d183ed",
      "2e92c1052e6d4674b5ba833adae960f4",
      "3fa48917b8704a3d9cec66760ed2defd",
      "dbac39be46e941629dc34fc9082e8e6a",
      "9c9396faccd44a63a8c89467b9a0371d",
      "3f9d475fe4004ca6be1971a8d062b0da",
      "46538dc6e20046eb8bb9e8d970a7e3df",
      "69fd922f66504292806f6431a554162b",
      "7887b99dd3004798ac49a4b5dba395b9"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:54:00.456824Z",
     "iopub.status.busy": "2024-10-31T10:54:00.456502Z",
     "iopub.status.idle": "2024-10-31T10:54:01.263634Z",
     "shell.execute_reply": "2024-10-31T10:54:01.262747Z",
     "shell.execute_reply.started": "2024-10-31T10:54:00.456790Z"
    },
    "id": "B14lz77Hoe3X",
    "outputId": "12fdf302-cd95-44d4-e838-33b9931688f4",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 107478 (80.0%)\n",
      "Validation set size: 13435 (10.0%)\n",
      "Test set size: 13435 (10.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 107478/107478 [00:00<00:00, 5629102.37 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 13435/13435 [00:00<00:00, 4453174.83 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 13435/13435 [00:00<00:00, 4762951.08 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Initial split: 80% training, 20% for test + validation\n",
    "train_jokes, temp_jokes = train_test_split(\n",
    "    jokes_list,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: split the remaining 20% into validation (10%) and test (10%)\n",
    "val_jokes, test_jokes = train_test_split(\n",
    "    temp_jokes,\n",
    "    test_size=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create HuggingFace datasets\n",
    "train_dataset = Dataset.from_dict({'text': train_jokes})\n",
    "val_dataset = Dataset.from_dict({'text': val_jokes})\n",
    "test_dataset = Dataset.from_dict({'text': test_jokes})\n",
    "\n",
    "# Print dataset sizes to verify splits\n",
    "print(f\"Training set size: {len(train_dataset)} ({len(train_dataset)/len(jokes_list)*100:.1f}%)\")\n",
    "print(f\"Validation set size: {len(val_dataset)} ({len(val_dataset)/len(jokes_list)*100:.1f}%)\")\n",
    "print(f\"Test set size: {len(test_dataset)} ({len(test_dataset)/len(jokes_list)*100:.1f}%)\")\n",
    "\n",
    "# Optional: save datasets\n",
    "train_dataset.save_to_disk('train_dataset')\n",
    "val_dataset.save_to_disk('val_dataset')\n",
    "test_dataset.save_to_disk('test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525,
     "referenced_widgets": [
      "a5c5a3eaaf334e1089ea713b6e8a04f1",
      "ec4f9abc951e42a191291a5e87d35b9b",
      "e9d6b496578e436b98be6bdc98ef54ab",
      "b2c0f3e320b84a138ecc9d3038c39ff8",
      "e85456980bbb4b4fa490d0c61ecd3732",
      "39cb09ec34274bcbaecf1533dcbd945c",
      "72c06b7fcf98462e9ab351a4fee9fd55",
      "d738a30a593c49ffa3f95505b6b3efe2",
      "9a2d0832d729475e9f0d1219d7d8c7fb",
      "0a143b93e2b745d180d1821a7c8e5931",
      "c9ebfab4d73c47fc8065856ac6c86669",
      "c31a0a71eb374ed7bf4deb14d8f0b6fc",
      "bb3c6ba85d8842f790b3b84c6b1400e8",
      "e3c511d78ef04165a8cdbd70a7aa978e",
      "0f85c323115a496791bd283d27e983f5",
      "6faaf2dd2db440c5a0ffb1e1cbed583d",
      "6110cf51bf754339b59fdde197ae56c5",
      "9c6e5d0fc0134094974ebfefbb03edf1",
      "7e05f14e88524dd18a950d07a083b4ff",
      "da37b9273aaa4ee2ad46e9c201cf484d",
      "4b05a0f06703433a8632989c93156114",
      "557df207d71a47d4a87b6ba3b589b260",
      "3924490e512e4668a3a7830bfcf7e8a1",
      "cd7a2b29c20d4ecbb279d2e95c539be6",
      "12a5df5d3c6f4295815e3e577deb7891",
      "26e6969dbc1a401cabd49710d94d7947",
      "c8fc1d467f954669a974b7d7ac3fd022",
      "21edd04c87f84b149e1b2d1ad051e7cd",
      "f76f2f6e504c46a4a0143cf5b3c14c75",
      "d72c36ef7612498590c367d430a8de75",
      "bf640e3127684bc8bdb654fd7351523d",
      "2a3cb753d6d142ef903877dbfdaa2953",
      "eac01fd9499d4029872a1614953b9eb2",
      "6ad0aad4fa1f4a1981e6025b9f4bc3a4",
      "cf54586db8f547cba952f3bc1968d79b",
      "f2163826aa314ba0882d4bba90e5ddb2",
      "35ecb83a003348f1ba4fce7d232d1165",
      "b60120e0c8034c94a277a2e63009348e",
      "76ffa237f97d4d0fb40750c363dd2507",
      "ad77682b6279417eb73b5af7af17cc55",
      "5a3a430c21904f098e7bd7f8310bf5db",
      "51baa10c6ec646598e1d141107c1c36d",
      "c1c5828b495948558a0677409d5b57f7",
      "22f68528d8064708bffb94e41fd57668",
      "3f641c22fad840369e82031761e711cb",
      "64b4ebe1aa064e3cbb49eb38b921ddbf",
      "0550acd8b44646d98b504aa0f8c3e1be",
      "551e62cb053a4ba9a291fbb7bb63417b",
      "39be91dfce3442ac89da65d03f24c5ea",
      "b811bfcf177741b29377f0ed0266774f",
      "e417ff1bca1d40c98d561a5182b90d2a",
      "f4ab4600818d4d7793cf563e52092307",
      "5daadcd9badd427cacb2a4e69bb49fa7",
      "e33c346babbb49e6a880652145e43fa6",
      "444cb38acc2a4536a55656408b2ce664",
      "3430f503f594472ebfd7ba2619426bb4",
      "45b388f1c9b74df695d013dc4be73a0d",
      "84e616a8f4764ff39f8faf5661382978",
      "f790313008984744802841b5eecc2e49",
      "a5c91628cdbe4a81a0ab3e6f7cd0b163",
      "26c74c8629724242b7760a23bff31746",
      "00f8fe67833c4636a1e43f0d27a7f498",
      "1ec3b03399814ea584752c6600c5149b",
      "3bfd70a10c1744b39723d5b8606ae3a2",
      "b06128a5f4e449329b52bc57d19def0d",
      "6461dadd450c4e67b61126355d4805c3",
      "6d81495d405c47ec9aaf3a01a1170498",
      "80cd95b71fae42f6a02bf547e96ea1e5",
      "498b9cb7b8744651af044e188cc2be2f",
      "fe41e1ab095648d8aa4962d143e30131",
      "0d5973f3aa284b6eb2c0699d20c618e8",
      "1ed01b57d9b04e6297e317b781cd62d8",
      "eff94198d04d43b9b08781fc5a26d6cc",
      "01353a05a3164a2992c39b3647598c67",
      "541b332fea1c44efb6b3d9bdc4242acf",
      "90055d2ec65b45c08d92353020a440e6",
      "bd993f19a38d499ba5727dc854af0a24",
      "7bfc727a31a74f6580652ca95f5aee3d",
      "9c59ee08d7be4034924b00d95b02f0ea",
      "b3fdde54e9d84b30bf89f53429ffc301",
      "97a84a1534b142969e7a24df02632695",
      "50c1195a214b4249838a04006ca4babb",
      "848bdcd923f248cd9f94c1a48a348ee0",
      "814f15358a4541d5998116d24f9c0074",
      "37b927432f1f41bf89f811b3e03aa7ce",
      "c8b93cd1a1d1469091e97646b4ae2839",
      "13a3203259f341bb8426e6c02522614b",
      "ebe0dc4364664e72be5798fab8e5aba8",
      "e7974c72742e49d58e90351630791351",
      "02e069c5773d4ccab4bb042d7cd8056b",
      "17033bbc15d44379a31f7331ed961249",
      "3fcb253eb0c94438b37d4e418c288595",
      "28e5caa9ceab49e6a1f3dc7cda77ff59",
      "152592c69b9e4753a6a5b2237ac027cd",
      "b559cf135bdf41de81c64ae766f05470",
      "b905f46ae7d94685adea97e1885522f4",
      "570b947632d14a978bc90f19d1f44419",
      "4fb90b45a7bf4ed69c78d7ab18675a97",
      "e45943138887443e80b2b79db2df414c",
      "6f7c180b6d7d4ae0b5eadbcf0e2235c0",
      "1c0125c7a6f24091ac16663c14eae9df",
      "4180526e5fc34722b0cd5905c2aad493",
      "9afd75558a534a79a3135a431cf6025f",
      "dec6919017234e668988e6f17cda38e0",
      "f32c78a591df42ecbe996d6279b036cf",
      "2206c2ce8d04467884c32e8af4c212c8",
      "aadb492e9fc349619ae2bf7e8a72f92e",
      "5bb388f5f8ab41d8bd25c004a9283132",
      "017a6c666f9c442484b548f2c9cb3994",
      "a4bc3fcefed847a6bb75ce888bc300f3",
      "d5ab1d724e664279841e0567b6cdd57c",
      "ec6f784dd366446585ef5ad4800c9067",
      "7b7810cb778f41cfa700f5eda2bf0f31",
      "a09d5049e7804c88b7fe9058663a3955",
      "caf4448bbfbc426c9d503d7423a7a603",
      "17b538d81a4442b1b96254e57794f2ba",
      "59e201ab43bd4b4f956fe81cddb07fe9",
      "fb487b98b8074426b58d753a99238d72",
      "3ce64fb49f7c49c293c7296ffd4a6ced",
      "e88261367ddd4824b552f4a315b2faa4",
      "263d3e01f87d452592503758ebbd5091"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-10-31T10:54:02.377665Z",
     "iopub.status.busy": "2024-10-31T10:54:02.377350Z"
    },
    "id": "-N2zD_cGoe3X",
    "outputId": "42a99848-c389-4671-a849-363e6b0ba8ed",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing training set: 100%|██████████| 107478/107478 [00:01<00:00, 78349.90 examples/s]\n",
      "Tokenizing validation set: 100%|██████████| 13435/13435 [00:00<00:00, 63449.45 examples/s]\n",
      "Tokenizing test set: 100%|██████████| 13435/13435 [00:00<00:00, 95193.85 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample from tokenized training set:\n",
      "Input IDs shape: 33\n",
      "Attention mask shape: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 107478/107478 [00:00<00:00, 3560672.69 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 13435/13435 [00:00<00:00, 2672411.75 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 13435/13435 [00:00<00:00, 2691558.76 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset sizes:\n",
      "Training set: 107478 examples\n",
      "Validation set: 13435 examples\n",
      "Test set: 13435 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\") # Load GPT-2 tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token # Set the pad token to the end-of-sequence token\n",
    "\n",
    "# Define tokenization function\n",
    "def tokenize_function(examples): # Function to tokenize the text\n",
    "    return tokenizer( # Tokenize the text\n",
    "        examples['text'], # Extract the 'text' field\n",
    "        truncation=True, # Truncate the text if it exceeds the maximum length\n",
    "        padding=True, # Pad the text to the maximum length\n",
    "        max_length=512,  # Adjust this value if needed\n",
    "        return_tensors=None  # Return lists instead of tensors (required for batching)\n",
    "    )\n",
    "\n",
    "# Tokenize all datasets\n",
    "tokenized_train = train_dataset.map( # Tokenize the training set\n",
    "    tokenize_function, # Use the tokenization function\n",
    "    batched=True, # Tokenize in batches\n",
    "    desc=\"Tokenizing training set\" # Description for the progress bar\n",
    ")\n",
    "\n",
    "tokenized_val = val_dataset.map( # Tokenize the validation set\n",
    "    tokenize_function, # Use the tokenization function\n",
    "    batched=True, # Tokenize in batches\n",
    "    desc=\"Tokenizing validation set\" # Description for the progress bar\n",
    ")\n",
    "\n",
    "tokenized_test = test_dataset.map( # Tokenize the test set\n",
    "    tokenize_function, # Use the tokenization function\n",
    "    batched=True, # Tokenize in batches\n",
    "    desc=\"Tokenizing test set\" # Description for the progress bar\n",
    ")\n",
    "\n",
    "# Create data collator for dynamic padding\n",
    "data_collator = DataCollatorWithPadding( # Create a data collator\n",
    "    tokenizer=tokenizer, # Set the tokenizer\n",
    "    padding=True, # Enable padding\n",
    "    return_tensors=\"pt\" # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "# Print sample output to verify\n",
    "print(\"\\nSample from tokenized training set:\")\n",
    "print(\"Input IDs shape:\", len(tokenized_train[0]['input_ids']))\n",
    "print(\"Attention mask shape:\", len(tokenized_train[0]['attention_mask']))\n",
    "\n",
    "# Save tokenized datasets\n",
    "tokenized_train.save_to_disk('tokenized_train')\n",
    "tokenized_val.save_to_disk('tokenized_val')\n",
    "tokenized_test.save_to_disk('tokenized_test')\n",
    "\n",
    "# Print dataset sizes\n",
    "print(\"\\nDataset sizes:\")\n",
    "print(f\"Training set: {len(tokenized_train)} examples\")\n",
    "print(f\"Validation set: {len(tokenized_val)} examples\")\n",
    "print(f\"Test set: {len(tokenized_test)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "e301653980394cebaa783623062c176d",
      "1c4a3c5b89b84a81b504d6feac354f03",
      "4cd07b51e539488caf9510a370d12104",
      "27ca0600bbba4216bd3897e3e2eee097",
      "385c7be9229845bdaf267210f73d97a7",
      "641f21cb097b4e65a96362ee51fefbcc",
      "276ad66d754c43aa9ceec156d20c0572",
      "ac4289fe6faa46a39f39b5759ab3c289",
      "54da7c79f9ab48439196463163d2c666",
      "aa445a076bb44b62bf514a6e198dcb22",
      "28b66db7b8a14d5d859ef3a3920b4a85",
      "dd7dda77623c4e35bd7241eb9476e377",
      "cf4ec13b65ef4973b29d678223863328",
      "e2ee3d1677f542e48963694fd40196ce",
      "e1285c6c241542ee973371f266435cb1",
      "3dd42dac38964d0f8c5afee90b092bfd",
      "baf492efc3434acd8c26d4e86e04f7cf",
      "aeaf7bb7ceca4bafbcfb6c7d03d1a70c",
      "0aa1e46e98694d19bee4aeab5c03e100",
      "1eb82d14fbe744639707a6c2c8f28ab5",
      "f6b5119e482844168c4d4fda532e78de",
      "b6473331903a40c5aadc88b16fa7bdb3",
      "e14c4f16cbeb4098aa4f157aaf9a3604",
      "d164b459c4ad495487deba8e85c35ae9",
      "c9959d700f28475e86b9b670ed9e7367",
      "28a5b552fe914610ba581155bbc8eb97",
      "c7667a4314df4835b71d26a24f60cc3a",
      "610e05ef4f204b6bb8c30b2969c99f93",
      "b5c047321eec42c9ac1c300d00ed3a9c",
      "d340cf5239c344e598c2ccac65130f1a",
      "eb73994b0a8a4106af1fe66872e6919d",
      "fedf5a17149e405e8391536452af0178",
      "324dbd17f67642099e7efbc6a00463cd"
     ]
    },
    "id": "cNNEibzRQ7r8",
    "outputId": "d365cc6d-610d-486d-ffbb-8760335fa4ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 107478/107478 [00:01<00:00, 72793.24 examples/s]\n",
      "Filter: 100%|██████████| 13435/13435 [00:00<00:00, 74186.85 examples/s]\n",
      "Filter: 100%|██████████| 13435/13435 [00:00<00:00, 77224.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Randomly drop 60% of the data since the kernel is crashing without training being finished if the full dataset is used\n",
    "tokenized_train = tokenized_train.filter(lambda example, idx: random.random() < 0.4, with_indices=True)\n",
    "tokenized_val = tokenized_val.filter(lambda example, idx: random.random() < 0.4, with_indices=True)\n",
    "tokenized_test = tokenized_test.filter(lambda example, idx: random.random() < 0.4, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "yay3IkB5Q7sA"
   },
   "outputs": [],
   "source": [
    "random.seed(40)\n",
    "test_samples = random.sample(test_jokes, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTo_I6JfQ7sA",
    "outputId": "1a376a16-a029-4faf-81b6-7f5b8bc0cd0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['whats long and hard and full of semen a submarine',\n",
       " 'did you hear about the knifewielding madman who attacked a circus camp the other day he went straight for the juggler',\n",
       " 'would you like to make me wine join everyone stomping my grapes',\n",
       " 'yo mamas so fat she fell in love and broke it',\n",
       " 'i hate the word chicks can we politely call them ladies women please ladies nuts on your chin']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2Ox51FG_xe3"
   },
   "source": [
    "### Part 2\n",
    "\n",
    "Create a decoder model and train it using the joke-dataset. Try out different hyperparameters for the model, like the number of decoder blocks, hidden dimension, sequence length etc. Choose the model which gives you the best results. Log the results for the different hyperparameters combinations used. Submit the logs in a pdf. (18 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "odq7JRihoe3Y",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module): # Define the CausalSelfAttention class\n",
    "  def __init__(self, d_k,d_model, n_heads, max_len): # Constructor\n",
    "    super().__init__() # Initialize the base class\n",
    "    # Assume d_v =d_k\n",
    "    self.d_k=d_k # Set the value of d_k\n",
    "    self.n_heads = n_heads # Set the number of heads\n",
    "    self.key = nn. Linear (d_model, d_k*n_heads) # Linear layer for key\n",
    "    self.query = nn. Linear (d_model, d_k*n_heads) # Linear layer for query\n",
    "    self.value = nn. Linear (d_model, d_k*n_heads) # Linear layer for value\n",
    "    # final linear layer\n",
    "    self.fc=nn.Linear (d_k*n_heads, d_model) # Linear layer for the final output\n",
    "    # casual mask\n",
    "    # make it so that diagonal is 0\n",
    "    # this way we don't have to shift the inputs to make targets\n",
    "    cm=torch.tril(torch.ones(int(max_len),int(max_len))) # Lower triangular matrix\n",
    "    self.register_buffer(\"causal_mask\",  cm.view(1,1, int(max_len), int(max_len))) # Register the causal mask as a buffer\n",
    "\n",
    "  def forward(self, q, k, v, pad_mask=None): # Forward pass\n",
    "    q=self.query(q) # N x T x (hd_k)\n",
    "    k=self.key(k) # N x T x (hd_k)\n",
    "    v=self.value(v) # N x T x (hd_k)\n",
    "    N = q.shape[0] # Batch size\n",
    "    T = q.shape[1] # Sequence length\n",
    "    # change the shape to:\n",
    "    # (N, T, h, d_k) --> N, h, T, d_k)\n",
    "    # in order for matrix multiply to work properly\n",
    "    q=q.view (N, T, self.n_heads, self.d_k).transpose(1,2) # Transpose q\n",
    "    k=k.view (N, T, self.n_heads, self.d_k).transpose(1,2) # Transpose k\n",
    "    v=v.view (N, T, self.n_heads, self.d_k).transpose(1,2) # Transpose v\n",
    "    # Copute attention weights\n",
    "    # (N, h, T, d_k)   x  (N, h, d_k, T )  --> (N, h, T, T)\n",
    "    attn_scores = q@k.transpose(-2,-1)/math.sqrt(self.d_k) # Scaled dot product;  @ --> torch.matmul\n",
    "    if pad_mask is not None: # Check if a padding mask is provided\n",
    "      attn_scores = attn_scores.masked_fill(pad_mask[:,None,None,:] == 0, float('-inf')) # Mask the padding tokens\n",
    "    attn_scores = attn_scores.masked_fill(self.causal_mask[:, :, :T, :T] == 0, float('-inf')) # Mask the future tokens\n",
    "    attn_weights = F.softmax(attn_scores, dim =-1) # Compute the attention weights\n",
    "    # Compute attention-weighted values\n",
    "    # (N, h, T, T) x (N, h, T, d_k) --> (N, h, T, d_k)\n",
    "    A = attn_weights @ v # Matrix multiplication\n",
    "    # reshape it back before final linear layer\n",
    "    A = A.transpose(1,2)  # (N, T, h, d_k) --> (N, T, h, d_k)\n",
    "    A = A.contiguous(). view(N, T, self.d_k*self.n_heads) # (N, T, h*d_k) --> (N, T, hd_k)\n",
    "    # projection\n",
    "    return self.fc(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "uyVpA-7toe3Z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module): # Define the TransformerBlock class\n",
    "  def __init__(self, d_k, d_model, n_heads, max_len, dropout_prob = 0.1): # Constructor\n",
    "    super().__init__() # Initialize the base class\n",
    "    self.ln1 = nn.LayerNorm(d_model) # Layer normalization\n",
    "    self.ln2 = nn.LayerNorm(d_model) # Layer normalization\n",
    "    self.mha = CausalSelfAttention(d_k, d_model, n_heads, max_len) # Multi-head attention\n",
    "    self.ann = nn.Sequential( # Feedforward neural network\n",
    "        nn.Linear(d_model, d_model*4), # Linear layer\n",
    "        nn.GELU(), # GELU activation\n",
    "        nn.Linear(d_model*4, d_model), # Linear layer\n",
    "        nn.Dropout(dropout_prob), # Dropout layer\n",
    "    ) # End of the feedforward neural network\n",
    "    self.dropout = nn.Dropout(p=dropout_prob) # Dropout layer\n",
    "\n",
    "  def forward (self, x, pad_mask=None): # Forward pass\n",
    "    x = self.ln1(x + self.mha(x, x, x, pad_mask)) # Multi-head attention\n",
    "    x = self.ln2(x + self.ann(x)) # Feedforward neural network\n",
    "    x = self.dropout(x) # Dropout\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "rmyMlZzkoe3Z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module): # Define the PositionalEncoding class\n",
    "  def __init__(self, d_model, max_len =2048, dropout_prob=0.1): # Constructor\n",
    "    super().__init__() # Initialize the base class\n",
    "    self.dropout = nn.Dropout(p = dropout_prob) # Dropout layer\n",
    "    position = torch.arange(max_len).unsqueeze(1) # Positional encoding\n",
    "    i = torch.arange(0, d_model//2) # Index\n",
    "    pe = torch.zeros(1, max_len, d_model) # Initialize the positional encoding\n",
    "    pe[0, :, 0::2] = torch.sin(position / (10000)**(2*i/d_model)) # Compute the positional encoding\n",
    "    pe[0, :, 1::2] = torch.cos(position / (10000)**(2*i/d_model)) # Compute the positional encoding\n",
    "    self.register_buffer('pe', pe) # Register the positional encoding as a buffer\n",
    "\n",
    "  def forward(self, x): # Forward pass\n",
    "    # x.shape : N x T x D\n",
    "    x = x + self.pe[:, :x.size(1), :] # Add positional encoding\n",
    "    return self.dropout(x) # Return the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "O2lKa1KWoe3Z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module): # Define the Decoder class\n",
    "  def __init__(self, vocab_size, max_len, d_k, d_model, n_heads, n_layers, dropout_prob): # Constructor\n",
    "    super().__init__() # Initialize the base class\n",
    "    self.embedding=nn.Embedding(vocab_size, d_model) # Embedding layer\n",
    "    self.pos_encoding=PositionalEncoding(d_model, max_len, dropout_prob) # Positional encoding\n",
    "    transformer_blocks=[TransformerBlock(d_k, d_model, n_heads, max_len, dropout_prob) for _ in range(n_layers) ] # Transformer blocks\n",
    "    self.transformer_blocks = nn.Sequential(*transformer_blocks) # Sequential model\n",
    "    self.ln = nn.LayerNorm(d_model) # Layer normalization\n",
    "    self.fc = nn.Linear(d_model, vocab_size) # Linear layer\n",
    "\n",
    "  def forward(self, x, pad_mask=None): # Forward pass\n",
    "    x=self.embedding(x) # Embedding\n",
    "    x=self.pos_encoding(x) # Positional encoding\n",
    "    for block in self.transformer_blocks: # Iterate over the transformer blocks\n",
    "      x = block(x, pad_mask) # Transformer block\n",
    "    x = self.ln(x) # Layer normalization\n",
    "    x = self.fc(x)  # many-to-many --> many-to-many\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "tN9_WSfXsP3k",
    "outputId": "33fd9973-bf0c-453b-8a40-8fd3aa5cdca6",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1660 SUPER'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# Show the device name\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "AtCz9Fxxoe3Z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_transformer_decoder(d_k, d_model, n_heads, n_layers, dropout_prob): # Define the create_transformer_decoder function\n",
    "    \"\"\"\n",
    "    Create and return a Transformer Decoder model based on the input hyperparameters.\n",
    "\n",
    "    Args:\n",
    "    vocab_size (int): The size of the vocabulary.\n",
    "    max_len (int): Maximum length of the input sequence.\n",
    "    d_k (int): Dimension of the keys/queries.\n",
    "    d_model (int): Dimension of the model (hidden size).\n",
    "    n_heads (int): Number of attention heads.\n",
    "    n_layers (int): Number of Transformer layers.\n",
    "    dropout_prob (float): Dropout probability.\n",
    "    device (str): Device to run the model on (e.g., 'cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "    nn.Module: The initialized Transformer Decoder model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Decoder(\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        max_len=tokenizer.model_max_length,\n",
    "        d_k=d_k,\n",
    "        d_model=d_model,\n",
    "        n_heads=n_heads,\n",
    "        n_layers=n_layers,\n",
    "        dropout_prob=dropout_prob\n",
    "    )\n",
    "\n",
    "    # Move the model to the specified device (e.g., CPU or GPU)\n",
    "    model.to(device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "0mEIUg7_1L4z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_data_for_training(dataset, seq_length): # Define the prepare_data_for_training function\n",
    "    \"\"\"\n",
    "    Prepare dataset for training by converting to appropriate format.\n",
    "    Args:\n",
    "        dataset: Dictionary containing 'input_ids' and 'attention_mask'\n",
    "        seq_length: Target sequence length for padding/truncation\n",
    "    Returns:\n",
    "        TensorDataset with input_ids and attention_mask\n",
    "    \"\"\"\n",
    "    input_ids = dataset['input_ids'] # Extract input IDs\n",
    "    attention_mask = dataset['attention_mask'] # Extract attention mask\n",
    "\n",
    "    # Initialize lists for padded sequences\n",
    "    padded_inputs = [] # Initialize an empty list\n",
    "    padded_masks = [] # Initialize an empty list\n",
    "\n",
    "    # Process each sequence individually\n",
    "    for seq, mask in zip(input_ids, attention_mask):\n",
    "        # Convert to list if not already\n",
    "        seq = list(seq)\n",
    "        mask = list(mask)\n",
    "\n",
    "        if len(seq) > seq_length: # Check if the sequence length exceeds the target length\n",
    "            # Truncate\n",
    "            padded_seq = seq[:seq_length] # Truncate the sequence\n",
    "            padded_mask = mask[:seq_length] # Truncate the mask\n",
    "        else:\n",
    "            # Pad\n",
    "            padding_length = seq_length - len(seq) # Calculate the padding length\n",
    "            padded_seq = seq + [0] * padding_length  # Pad with zeros\n",
    "            padded_mask = mask + [0] * padding_length # Pad with zeros\n",
    "\n",
    "        padded_inputs.append(padded_seq) # Append the padded sequence\n",
    "        padded_masks.append(padded_mask) # Append the padded mask\n",
    "\n",
    "    # Convert to numpy arrays after padding\n",
    "    padded_inputs = np.array(padded_inputs, dtype=np.int64) # Convert to a NumPy array\n",
    "    padded_masks = np.array(padded_masks, dtype=np.int64) # Convert to a NumPy array\n",
    "\n",
    "    return torch.utils.data.TensorDataset( # Return a TensorDataset\n",
    "        torch.LongTensor(padded_inputs), # Convert to a PyTorch tensor\n",
    "        torch.LongTensor(padded_masks) # Convert to a PyTorch tensor\n",
    "    )\n",
    "\n",
    "def calculate_l2_loss(model, lambda_l2=0.01): # Define the calculate_l2_loss function\n",
    "    \"\"\"\n",
    "    Calculate L2 regularization loss for model parameters.\n",
    "    \"\"\"\n",
    "    l2_loss = 0\n",
    "    for param in model.parameters():\n",
    "        l2_loss += torch.norm(param, p=2) # Calculate the L2 norm of the parameter\n",
    "    return lambda_l2 * l2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "iJM4cLJ5mOHZ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_transformer(\n",
    "    d_k: int, # Dimension of key/query vectors\n",
    "    d_model: int, # Model dimension\n",
    "    n_heads: int, # Number of attention heads\n",
    "    n_layers: int, # Number of transformer layers\n",
    "    dropout_prob: float, # Dropout probability\n",
    "    learning_rate: float, # Learning rate for optimizer\n",
    "    num_epochs: int, # Number of training epochs\n",
    "    batch_size: int, # Batch size for training\n",
    "    seq_length: int, # Maximum sequence length for padding/truncation\n",
    "    save_path: str = 'best_model.pt', # Path to save best model\n",
    "    early_stopping_patience: int = 3, # Number of epochs to wait before early stopping\n",
    "    weight_decay: float = 0.01, # L2 regularization factor for optimizer\n",
    "    lambda_l2: float = 0.01 # L2 regularization factor for loss function\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Train a transformer model with added L2 regularization and improved initialization.\n",
    "\n",
    "    Args:\n",
    "        d_k: Dimension of key/query/value vectors\n",
    "        d_model: Model dimension\n",
    "        n_heads: Number of attention heads\n",
    "        n_layers: Number of transformer layers\n",
    "        dropout_prob: Dropout probability\n",
    "        learning_rate: Learning rate for optimizer\n",
    "        num_epochs: Number of training epochs\n",
    "        batch_size: Batch size for training\n",
    "        seq_length: Maximum sequence length for padding/truncation\n",
    "        save_path: Path to save best model\n",
    "        early_stopping_patience: Number of epochs to wait before early stopping\n",
    "        weight_decay: L2 regularization factor for optimizer\n",
    "        lambda_l2: L2 regularization factor for loss function\n",
    "\n",
    "    Returns:\n",
    "        dict: Training history containing losses and metrics\n",
    "    \"\"\"\n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Check if GPU is available\n",
    "    print(f\"Using device: {device}\") # Print device\n",
    "\n",
    "    # Create model\n",
    "    model = create_transformer_decoder( # Create transformer model\n",
    "        d_k=d_k, # Dimension of key/query vectors\n",
    "        d_model=d_model, # Model dimension\n",
    "        n_heads=n_heads, # Number of attention heads\n",
    "        n_layers=n_layers, # Number of transformer layers\n",
    "        dropout_prob=dropout_prob # Dropout probability\n",
    "    ).to(device) # Move model to device\n",
    "\n",
    "    # Initialize weights using Xavier/Glorot initialization\n",
    "    def init_weights(m): # Initialize weights\n",
    "        if isinstance(m, nn.Linear): # If linear layer\n",
    "            torch.nn.init.xavier_uniform_(m.weight) # Use Xavier initialization\n",
    "            if m.bias is not None: # If bias is not None\n",
    "                torch.nn.init.zeros_(m.bias) # Initialize bias to zeros\n",
    "    model.apply(init_weights) # Apply weight initialization\n",
    "\n",
    "    # Log model parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters()) # Total parameters\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad) # Trainable parameters\n",
    "    print(f\"Total parameters: {total_params:,}\") # Print total parameters\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\") # Print trainable parameters\n",
    "\n",
    "    # Prepare datasets with specified sequence length\n",
    "    train_data = prepare_data_for_training(tokenized_train, seq_length) # Prepare training data\n",
    "    val_data = prepare_data_for_training(tokenized_val, seq_length) # Prepare validation data\n",
    "    test_data = prepare_data_for_training(tokenized_test, seq_length) # Prepare test data\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = torch.utils.data.DataLoader( # Training data loader\n",
    "        train_data, # Training data\n",
    "        batch_size=batch_size, # Batch size\n",
    "        shuffle=True, # Shuffle data\n",
    "        pin_memory=True, # Pin memory\n",
    "        num_workers=2 # Number of workers\n",
    "    )\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader( # Validation data loader\n",
    "        val_data, # Validation data\n",
    "        batch_size=batch_size, # Batch size\n",
    "        shuffle=False, # Do not Shuffle data\n",
    "        pin_memory=True, # Pin memory\n",
    "        num_workers=2 # Number of workers\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader( # Test data loader\n",
    "        test_data, # Test data\n",
    "        batch_size=batch_size, # Batch size\n",
    "        shuffle=False, # Do not Shuffle data\n",
    "        pin_memory=True, # Pin memory\n",
    "        num_workers=2 # Number of workers\n",
    "    )\n",
    "\n",
    "    # Initialize optimizer with weight decay\n",
    "    optimizer = torch.optim.AdamW( # AdamW optimizer\n",
    "        model.parameters(), # Model parameters\n",
    "        lr=learning_rate, # Learning rate\n",
    "        weight_decay=weight_decay, # Weight decay\n",
    "        betas=(0.9, 0.999), # Betas\n",
    "        eps=1e-8 # Epsilon\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id) # Cross entropy loss\n",
    "    scheduler = ReduceLROnPlateau( # Reduce LR on plateau\n",
    "        optimizer, # Optimizer\n",
    "        mode='min', # Mode\n",
    "        factor=0.5, # Factor\n",
    "        patience=2, # Patience\n",
    "        verbose=True, # Verbose\n",
    "        min_lr=1e-7 # Min LR\n",
    "    )\n",
    "\n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [], # Training loss\n",
    "        'train_reg_loss': [], # Training regularization loss\n",
    "        'val_loss': [], # Validation loss\n",
    "        'val_perplexity': [], # Validation perplexity\n",
    "        'learning_rates': [], # Learning rates\n",
    "        'test_loss': None, # Test loss\n",
    "        'test_perplexity': None # Test perplexity\n",
    "    }\n",
    "\n",
    "    # Early stopping variables\n",
    "    best_val_loss = float('inf') # Best validation loss\n",
    "    patience_counter = 0 # Patience counter\n",
    "    best_epoch = 0 # Best epoch\n",
    "\n",
    "    # Gradient scaler for mixed precision training\n",
    "    scaler = torch.cuda.amp.GradScaler() if device.type == 'cuda' else None # Gradient scaler\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs): # Epoch loop\n",
    "        model.train() # Set model to training mode\n",
    "        total_train_loss = 0 # Total training loss\n",
    "        total_reg_loss = 0 # Total regularization loss\n",
    "        train_steps = 0 # Training steps\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}') # Progress bar\n",
    "        for batch_idx, (input_ids, attention_mask) in enumerate(progress_bar): # Batch loop\n",
    "            try:\n",
    "                # Move batch to device\n",
    "                input_ids = input_ids.to(device) # Input IDs\n",
    "                attention_mask = attention_mask.to(device) # Attention mask\n",
    "\n",
    "                # Mixed precision training context\n",
    "                with torch.cuda.amp.autocast() if device.type == 'cuda' else nullcontext():\n",
    "                    # Forward pass\n",
    "                    outputs = model(input_ids, attention_mask) # Model outputs\n",
    "\n",
    "                    # Shift predictions and targets\n",
    "                    shift_logits = outputs[..., :-1, :].contiguous() # Shift logits\n",
    "                    shift_labels = input_ids[..., 1:].contiguous() # Shift labels\n",
    "\n",
    "                    # Calculate cross entropy loss\n",
    "                    ce_loss = criterion( # Cross entropy loss\n",
    "                        shift_logits.view(-1, tokenizer.vocab_size), # Flattened logits\n",
    "                        shift_labels.view(-1) # Flattened labels\n",
    "                    )\n",
    "\n",
    "                    # Add L2 regularization\n",
    "                    l2_loss = calculate_l2_loss(model, lambda_l2) # L2 regularization loss\n",
    "                    loss = ce_loss + l2_loss # Total loss\n",
    "\n",
    "                # Backward pass with gradient scaling\n",
    "                optimizer.zero_grad(set_to_none=True) # Zero gradients\n",
    "                if scaler is not None: # Use gradient scaler\n",
    "                    scaler.scale(loss).backward() # Backward pass\n",
    "                    scaler.unscale_(optimizer) # Unscaled gradients\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Clip gradients\n",
    "                    scaler.step(optimizer) # Step optimizer\n",
    "                    scaler.update() # Update scaler\n",
    "                else: # No gradient scaler\n",
    "                    loss.backward() # Backward pass\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Clip gradients\n",
    "                    optimizer.step() # Step optimizer\n",
    "\n",
    "                # Update metrics\n",
    "                if not torch.isnan(loss): # Skip NaN losses\n",
    "                    total_train_loss += ce_loss.item() # Accumulate CE loss\n",
    "                    total_reg_loss += l2_loss.item() # Accumulate L2 loss\n",
    "                    train_steps += 1 # Increment train steps\n",
    "\n",
    "                    # Update progress bar\n",
    "                    progress_bar.set_postfix({ # Update progress bar\n",
    "                        'ce_loss': ce_loss.item(), # CE loss\n",
    "                        'l2_loss': l2_loss.item(), # L2 loss\n",
    "                        'lr': optimizer.param_groups[0]['lr'] # Learning rate\n",
    "                    })\n",
    "                else: # NaN loss\n",
    "                    print(f'Warning: NaN loss at epoch {epoch + 1}, batch {batch_idx}') # Print warning\n",
    "\n",
    "            except RuntimeError as e: # Catch OOM errors\n",
    "                print(f\"Error in training batch {batch_idx}: {str(e)}\") # Print error message\n",
    "                continue # Skip the current batch\n",
    "\n",
    "        # Calculate average losses\n",
    "        avg_train_loss = total_train_loss / train_steps # Average training loss\n",
    "        avg_reg_loss = total_reg_loss / train_steps # Average regularization loss\n",
    "        history['train_loss'].append(avg_train_loss) # Log training loss\n",
    "        history['train_reg_loss'].append(avg_reg_loss) # Log regularization loss\n",
    "        history['learning_rates'].append(optimizer.param_groups[0]['lr']) # Log learning rate\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval() # Set model to evaluation mode\n",
    "        total_val_loss = 0 # Total validation loss\n",
    "        val_steps = 0 # Validation steps\n",
    "\n",
    "        with torch.no_grad(): # Disable gradients for validation\n",
    "            for input_ids, attention_mask in tqdm(val_loader, desc='Validation'): # Validation loop\n",
    "                try: # Try block\n",
    "                    input_ids = input_ids.to(device) # Move to device\n",
    "                    attention_mask = attention_mask.to(device) # Move to device\n",
    "                    outputs = model(input_ids, attention_mask) # Forward pass\n",
    "                    shift_logits = outputs[..., :-1, :].contiguous() # Shift logits\n",
    "                    shift_labels = input_ids[..., 1:].contiguous() # Shift labels\n",
    "\n",
    "                    loss = criterion( # Calculate validation loss\n",
    "                        shift_logits.view(-1, tokenizer.vocab_size), # Flatten logits\n",
    "                        shift_labels.view(-1) # Flatten labels\n",
    "                    )\n",
    "\n",
    "                    if not torch.isnan(loss): # Skip NaN losses\n",
    "                        total_val_loss += loss.item() # Accumulate validation loss\n",
    "                        val_steps += 1 # Increment validation steps\n",
    "\n",
    "                except RuntimeError as e: # Catch OOM errors\n",
    "                    print(f\"Error in validation batch: {str(e)}\") # Print error message\n",
    "                    continue # Skip the current batch\n",
    "\n",
    "        # Calculate validation metrics\n",
    "        avg_val_loss = total_val_loss / val_steps # Average validation loss\n",
    "        val_perplexity = torch.exp(torch.tensor(avg_val_loss)) # Validation perplexity\n",
    "\n",
    "        history['val_loss'].append(avg_val_loss) # Log validation loss\n",
    "        history['val_perplexity'].append(val_perplexity.item()) # Log validation perplexity\n",
    "\n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(avg_val_loss) # Step scheduler\n",
    "\n",
    "        # Print epoch results\n",
    "        print(f'\\nEpoch {epoch + 1} Results:') # Print epoch results\n",
    "        print(f'Training CE loss: {avg_train_loss:.4f}') # Print training loss\n",
    "        print(f'Training L2 loss: {avg_reg_loss:.4f}') # Print regularization loss\n",
    "        print(f'Validation loss: {avg_val_loss:.4f}') # Print validation loss\n",
    "        print(f'Validation perplexity: {val_perplexity:.4f}') # Print validation perplexity\n",
    "        print(f'Learning rate: {optimizer.param_groups[0][\"lr\"]:.2e}') # Print learning rate\n",
    "\n",
    "        # Model checkpointing and early stopping\n",
    "        if avg_val_loss < best_val_loss: # Save best model\n",
    "            best_val_loss = avg_val_loss # Update best validation loss\n",
    "            best_epoch = epoch + 1 # Update best epoch\n",
    "            torch.save({ # Save checkpoint\n",
    "                'epoch': epoch, # Epoch\n",
    "                'model_state_dict': model.state_dict(), # Model state\n",
    "                'optimizer_state_dict': optimizer.state_dict(), # Optimizer state\n",
    "                'scheduler_state_dict': scheduler.state_dict(), # Scheduler state\n",
    "                'val_loss': best_val_loss, # Validation loss\n",
    "            }, save_path) # Save path\n",
    "            patience_counter = 0 # Reset patience counter\n",
    "            print(f'Saved new best model to {save_path}') # Print save message\n",
    "        else: # No improvement\n",
    "            patience_counter += 1 # Increment patience counter\n",
    "            if patience_counter >= early_stopping_patience: # Early stopping\n",
    "                print(f'\\nEarly stopping triggered after {epoch + 1} epochs') # Print early stopping message\n",
    "                print(f'Best validation loss: {best_val_loss:.4f} at epoch {best_epoch}') # Print best validation loss\n",
    "                break # Break the training loop\n",
    "\n",
    "    # Load best model for testing\n",
    "    print(\"\\nLoading best model for final evaluation...\") # Load best model\n",
    "    checkpoint = torch.load(save_path) # Load checkpoint\n",
    "    model.load_state_dict(checkpoint['model_state_dict']) # Load model state\n",
    "    model.eval() # Set model to evaluation mode\n",
    "\n",
    "    # Test set evaluation\n",
    "    print(\"Evaluating on test set...\") # Test phase\n",
    "    total_test_loss = 0 # Total test loss\n",
    "    test_steps = 0 # Number of test steps\n",
    "\n",
    "    with torch.no_grad(): # Disable gradients for testing\n",
    "        for input_ids, attention_mask in tqdm(test_loader, desc='Testing'): # Forward pass\n",
    "            try: # Forward pass\n",
    "                input_ids = input_ids.to(device) # Move to device\n",
    "                attention_mask = attention_mask.to(device) # Forward pass\n",
    "\n",
    "                outputs = model(input_ids, attention_mask) # Forward pass\n",
    "\n",
    "                shift_logits = outputs[..., :-1, :].contiguous() # Ignore last token\n",
    "                shift_labels = input_ids[..., 1:].contiguous() # Ignore first token\n",
    "\n",
    "                loss = criterion( # Calculate test loss\n",
    "                    shift_logits.view(-1, tokenizer.vocab_size), \n",
    "                    shift_labels.view(-1)# Flatten the target sequence\n",
    "                )\n",
    "\n",
    "                if not torch.isnan(loss): # Skip NaN losses\n",
    "                    total_test_loss += loss.item() # Accumulate test loss\n",
    "                    test_steps += 1 # Increment test steps\n",
    "\n",
    "            except RuntimeError as e: # Catch OOM errors\n",
    "                print(f\"Error in test batch: {str(e)}\") # Print error message\n",
    "                continue # Skip the current batch\n",
    "\n",
    "    # Calculate and log final metrics\n",
    "    avg_test_loss = total_test_loss / test_steps # Calculate average test loss\n",
    "    test_perplexity = torch.exp(torch.tensor(avg_test_loss)) # Calculate test perplexity\n",
    "\n",
    "    history['test_loss'] = avg_test_loss # Log test loss\n",
    "    history['test_perplexity'] = test_perplexity.item() # Log test perplexity\n",
    "\n",
    "    print('\\nFinal Test Results:') # Print final test results\n",
    "    print(f'Test loss: {avg_test_loss:.4f}') # Print test loss\n",
    "    print(f'Test perplexity: {test_perplexity:.4f}') # Print test perplexity\n",
    "    print(f'Best validation loss: {best_val_loss:.4f} at epoch {best_epoch}') # Print best validation loss\n",
    "\n",
    "    return history # Return training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "nyBgosV4Ai8P"
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # Disable tokenizers parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLWmF0kHQ7sB"
   },
   "source": [
    "For the experiments, use less data points. After the hyperparameter tuning has been done, the model with best hyperparameters will be trained on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "zGK5X5aFQ7sB"
   },
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\" # Set CUDA memory management to expandable segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "t4CtqYJTAi8P"
   },
   "outputs": [],
   "source": [
    "def experiment_tracker( # Experiment tracker\n",
    "    hidden_dims: List[int], # Hidden dimensions\n",
    "    hidden_layers: List[int], # Hidden layers\n",
    "    n_heads_list: List[int], # Number of heads\n",
    "    seq_length: List[int], # Sequence length\n",
    "    base_save_path: str = 'experiments' # Base save path\n",
    ") -> str: # Return type\n",
    "    \"\"\"\n",
    "    Run experiments with different hyperparameter combinations and track results.\n",
    "\n",
    "    Args:\n",
    "        hidden_dims: List of hidden dimensions to try\n",
    "        hidden_layers: List of number of layers to try\n",
    "        n_heads_list: List of number of heads to try\n",
    "        seq_length: List of sequence lengths to try for padding/truncation\n",
    "        base_save_path: Base directory to save experiments\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the best overall model\n",
    "    \"\"\"\n",
    "    # Check and print CUDA availability\n",
    "    cuda_available = torch.cuda.is_available() # Check if CUDA is available\n",
    "    print(f\"CUDA Available: {cuda_available}\") # Print CUDA availability\n",
    "\n",
    "    # Create experiment directory with timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S') # Timestamp\n",
    "    exp_dir = os.path.join(base_save_path, f'experiment_{timestamp}') # Experiment directory\n",
    "    os.makedirs(exp_dir, exist_ok=True) # Create experiment directory\n",
    "\n",
    "    # Initialize PDF for logging\n",
    "    pdf = FPDF() # Initialize PDF\n",
    "    pdf.add_page() # Add page\n",
    "    pdf.set_font(\"Arial\", size=12) # Set font\n",
    "\n",
    "    # Store all results\n",
    "    all_results = [] # All results\n",
    "    skipped_experiments = [] # Skipped experiments\n",
    "\n",
    "    # Generate all combinations of hyperparameters\n",
    "    combinations = list(itertools.product(hidden_layers, hidden_dims, n_heads_list, seq_length)) # Generate combinations\n",
    "    total_experiments = len(combinations) # Total experiments\n",
    "\n",
    "    # Log experiment setup\n",
    "    setup_info = f\"\"\" # Log experiment setup\n",
    "    Experiment Started at: {timestamp} # Experiment timestamp\n",
    "    Number of combinations: {total_experiments} # Total combinations\n",
    "    Hidden layers tested: {hidden_layers} # Hidden layers\n",
    "    Hidden dimensions tested: {hidden_dims} # Hidden dimensions\n",
    "    Number of heads tested: {n_heads_list} # Number of heads\n",
    "    Sequence lengths tested: {seq_length} # Sequence lengths\n",
    "    CUDA Available: {cuda_available} # CUDA availability\n",
    "    \"\"\"\n",
    "    pdf.multi_cell(0, 10, setup_info) # Multi-cell print\n",
    "\n",
    "    best_test_perplexity = float('inf') # Best test perplexity\n",
    "    best_model_path = None # Best model path\n",
    "    best_model_hyperparams = None # Best model hyperparameters\n",
    "\n",
    "    print(\"\\nStarting experiments...\") # Print start message\n",
    "    print(f\"Total combinations to test: {total_experiments}\") # Print total combinations\n",
    "    print(\"Parameters being tested:\") # Print parameters\n",
    "    print(f\"- Hidden layers: {hidden_layers}\") # Print hidden layers\n",
    "    print(f\"- Hidden dimensions: {hidden_dims}\") # Print hidden dimensions\n",
    "    print(f\"- Number of heads: {n_heads_list}\") # Print number of heads\n",
    "    print(f\"- Sequence lengths: {seq_length}\\n\") # Print sequence lengths\n",
    "\n",
    "    # Run experiments for each combination\n",
    "    for experiment_num, (n_layers, d_model, n_heads, seq_len) in enumerate(combinations, 1): # Experiment loop\n",
    "        print(f\"\\nExperiment {experiment_num}/{total_experiments}\") # Print experiment number\n",
    "        print(\"Current parameters being tested:\") # Print current parameters\n",
    "        print(f\"- Number of layers: {n_layers}\") # Print number of layers\n",
    "        print(f\"- Hidden dimension: {d_model}\") # Print hidden dimension\n",
    "        print(f\"- Number of heads: {n_heads}\") # Print number of heads\n",
    "        print(f\"- Sequence length: {seq_len}\") # Print sequence length\n",
    "\n",
    "        # Clear CUDA cache before each experiment\n",
    "        if cuda_available: # If CUDA is available\n",
    "            torch.cuda.empty_cache() # Clear CUDA cache\n",
    "\n",
    "        # Check if sufficient GPU memory is available\n",
    "        try:\n",
    "            # Simulate model memory allocation to check available memory\n",
    "            model_memory_estimate = (\n",
    "                d_model * 4 *  # Input tensor\n",
    "                (n_layers * 3 +  # Transformer layers\n",
    "                 n_layers * 2)  # Other components\n",
    "            )\n",
    "            available_memory = torch.cuda.get_device_properties(0).total_memory # Total memory\n",
    "\n",
    "            if model_memory_estimate > available_memory * 0.98:  # 9% of total memory\n",
    "                skipped_info = ( # Skipped info\n",
    "                    f\"Skipping Experiment {experiment_num}/{total_experiments}: Insufficient GPU memory\\n\" # Skipped message\n",
    "                    f\"Layers: {n_layers}, Dim: {d_model}, Heads: {n_heads}, Seq Length: {seq_len}\\n\" # Parameters\n",
    "                    f\"Estimated Memory: {model_memory_estimate / (1024**2):.2f} MB\\n\" # Estimated memory\n",
    "                    f\"Available Memory: {available_memory / (1024**2):.2f} MB\" # Available memory\n",
    "                )\n",
    "                skipped_experiments.append(skipped_info) # Append skipped info\n",
    "                print(skipped_info) # Print skipped info\n",
    "                continue # Skip the current experiment\n",
    "\n",
    "        except RuntimeError as e: # Catch memory allocation errors\n",
    "            skipped_info = ( # Skipped info\n",
    "                f\"Skipping Experiment {experiment_num}/{total_experiments} due to memory allocation error\\n\" # Skipped message\n",
    "                f\"Layers: {n_layers}, Dim: {d_model}, Heads: {n_heads}, Seq Length: {seq_len}\\n\" # Parameters\n",
    "                f\"Error: {str(e)}\" # Error message\n",
    "            )\n",
    "            skipped_experiments.append(skipped_info) # Append skipped info\n",
    "            print(skipped_info) # Print skipped info\n",
    "            continue # Skip the current experiment\n",
    "\n",
    "        # Create model-specific save path\n",
    "        model_save_path = os.path.join( # Model save path\n",
    "            exp_dir, # Experiment directory\n",
    "            f'model_l{n_layers}_d{d_model}_h{n_heads}_s{seq_len}.pt' # Model path\n",
    "        )\n",
    "\n",
    "        # Capture stdout to redirect prints to PDF\n",
    "        stdout_capture = io.StringIO() # Stdout capture\n",
    "        with redirect_stdout(stdout_capture): # Redirect stdout\n",
    "            print(f\"\\nExperiment {experiment_num}/{total_experiments}\") # Print experiment number\n",
    "            print(f\"Parameters: layers={n_layers}, d_model={d_model}, n_heads={n_heads}, seq_length={seq_len}\") # Print parameters\n",
    "\n",
    "            # Call training function\n",
    "            d_k = d_model // n_heads # Calculate key/query dimension\n",
    "            try: # Try training\n",
    "                history = train_transformer( # Train transformer\n",
    "                    d_k=d_k, # Key/Query dimension\n",
    "                    d_model=d_model, # Model dimension\n",
    "                    n_heads=n_heads, # Number of heads\n",
    "                    n_layers=n_layers, # Number of layers\n",
    "                    dropout_prob=0.1, # Dropout probability\n",
    "                    learning_rate=1e-5, # Learning rate\n",
    "                    num_epochs=8, # Number of epochs\n",
    "                    batch_size=8, # Batch size\n",
    "                    seq_length=seq_len, # Sequence length\n",
    "                    save_path=model_save_path, # Save path\n",
    "                    weight_decay=0.01, # Weight decay\n",
    "                    lambda_l2=0.01 # L2 regularization factor\n",
    "                )\n",
    "            except Exception as e: # Catch errors\n",
    "                skipped_info = ( # Skipped info\n",
    "                    f\"Experiment {experiment_num}/{total_experiments} failed during training\\n\" # Skipped message\n",
    "                    f\"Layers: {n_layers}, Dim: {d_model}, Heads: {n_heads}, Seq Length: {seq_len}\\n\" # Parameters\n",
    "                    f\"Error: {str(e)}\" # Error message\n",
    "                )\n",
    "                skipped_experiments.append(skipped_info) # Append skipped info\n",
    "                print(skipped_info) # Print skipped info\n",
    "                continue # Skip the current experiment\n",
    "\n",
    "        # Get captured output\n",
    "        training_log = stdout_capture.getvalue()\n",
    "\n",
    "        # Add experiment results to PDF\n",
    "        pdf.add_page() # Add page\n",
    "        pdf.multi_cell(0, 10, f\"\\nExperiment {experiment_num}/{total_experiments} Results:\") # Print experiment results\n",
    "        pdf.multi_cell(0, 10, f\"Parameters: layers={n_layers}, d_model={d_model}, n_heads={n_heads}, seq_length={seq_len}\") # Print parameters\n",
    "        pdf.multi_cell(0, 10, training_log) # Print training log\n",
    "\n",
    "        # Track best model\n",
    "        test_perplexity = history['test_perplexity'] # Test perplexity\n",
    "        result = { # Result\n",
    "            'n_layers': n_layers, # Number of layers\n",
    "            'd_model': d_model, # Model dimension\n",
    "            'n_heads': n_heads, # Number of heads\n",
    "            'seq_length': seq_len, # Sequence length\n",
    "            'test_perplexity': test_perplexity, # Test perplexity\n",
    "            'model_path': model_save_path, # Model path\n",
    "            'd_k': d_k # Key/Query dimension\n",
    "        }\n",
    "        all_results.append(result) # Append result\n",
    "\n",
    "        if test_perplexity < best_test_perplexity: # Update best model\n",
    "            best_test_perplexity = test_perplexity # Update best test perplexity\n",
    "            best_model_path = model_save_path # Best model path\n",
    "            best_model_hyperparams = result # Best model hyperparameters\n",
    "\n",
    "    # Save the best model as best_best_model.pt\n",
    "    if best_model_path: # If best model path\n",
    "        final_best_path = os.path.join(exp_dir, 'best_best_model.pt') # Final best model path\n",
    "        torch.save( # Save best model\n",
    "            torch.load(best_model_path), # Load best model\n",
    "            final_best_path # Final best model path\n",
    "        )\n",
    "    else: # No successful experiments\n",
    "        final_best_path = None # No best model path\n",
    "        print(\"No successful experiments completed.\") # Print no successful experiments\n",
    "\n",
    "    # Print best model hyperparameters\n",
    "    if best_model_hyperparams: # If best model hyperparameters\n",
    "        print(\"\\nBest Model Hyperparameters:\") # Print best model hyperparameters\n",
    "        print(f\"Layers: {best_model_hyperparams['n_layers']}\") # Print number of layers\n",
    "        print(f\"Hidden Dimension: {best_model_hyperparams['d_model']}\") # Print hidden dimension\n",
    "        print(f\"Number of Heads: {best_model_hyperparams['n_heads']}\") # Print number of heads\n",
    "        print(f\"Sequence Length: {best_model_hyperparams['seq_length']}\") # Print sequence length\n",
    "        print(f\"Key/Query Dimension (d_k): {best_model_hyperparams['d_k']}\") # Print key/query dimension\n",
    "        print(f\"Test Perplexity: {best_model_hyperparams['test_perplexity']:.4f}\") # Print test perplexity\n",
    "\n",
    "    # Add summary to PDF\n",
    "    pdf.add_page() # Add page\n",
    "    pdf.multi_cell(0, 10, \"\\nExperiment Summary:\") # Print experiment summary\n",
    "    for result in sorted(all_results, key=lambda x: x['test_perplexity']): # Sort results\n",
    "        summary = f\"\"\" # Summary\n",
    "        Layers: {result['n_layers']} # Number of layers\n",
    "        Hidden Dimension: {result['d_model']} # Hidden dimension\n",
    "        Number of Heads: {result['n_heads']} # Number of heads\n",
    "        Sequence Length: {result['seq_length']} # Sequence length\n",
    "        Key/Query Dimension (d_k): {result['d_k']} # Key/Query dimension\n",
    "        Test Perplexity: {result['test_perplexity']:.4f} # Test perplexity\n",
    "        Model Path: {result['model_path']} # Model path\n",
    "        \"\"\"\n",
    "        pdf.multi_cell(0, 10, summary) # Print summary\n",
    "\n",
    "    # Add skipped experiments to PDF\n",
    "    if skipped_experiments: # If skipped experiments\n",
    "        pdf.add_page() # Add page\n",
    "        pdf.multi_cell(0, 10, \"\\nSkipped Experiments:\") # Print skipped experiments\n",
    "        for skipped_exp in skipped_experiments: # Print skipped experiments\n",
    "            pdf.multi_cell(0, 10, skipped_exp) # Print skipped experiments\n",
    "\n",
    "    # Save final results\n",
    "    results_path = os.path.join(exp_dir, 'experiment_results.json') # Results path\n",
    "    with open(results_path, 'w') as f: # Save results\n",
    "        json.dump({ # Save results\n",
    "            'completed_experiments': all_results, # Completed experiments\n",
    "            'skipped_experiments': skipped_experiments # Skipped experiments\n",
    "        }, f, indent=4) # Save results\n",
    "\n",
    "    # Save PDF\n",
    "    pdf_path = os.path.join(exp_dir, 'experiment_log.pdf') # PDF path\n",
    "    pdf.output(pdf_path) # Save PDF\n",
    "\n",
    "    print(f\"\\nExperiment completed!\") # Print completion message\n",
    "    if final_best_path: # If best model path\n",
    "        print(f\"Best model saved to: {final_best_path}\") # Print best model path\n",
    "    print(f\"Full logs saved to: {pdf_path}\") # Print PDF path\n",
    "    print(f\"Results saved to: {results_path}\") # Print results path\n",
    "\n",
    "    return final_best_path # Return best model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICzjq31ZQ7sD",
    "outputId": "b466f997-a044-43ed-c7f6-4c59a3c7b26f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "\n",
      "Starting experiments...\n",
      "Total combinations to test: 24\n",
      "Parameters being tested:\n",
      "- Hidden layers: [2, 4]\n",
      "- Hidden dimensions: [16, 32, 64]\n",
      "- Number of heads: [2, 4]\n",
      "- Sequence lengths: [256, 512]\n",
      "\n",
      "\n",
      "Experiment 1/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 2\n",
      "- Hidden dimension: 16\n",
      "- Number of heads: 2\n",
      "- Sequence length: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [05:52<00:00, 15.21it/s, ce_loss=9.3, l2_loss=9.61, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 79.08it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [05:53<00:00, 15.16it/s, ce_loss=7.34, l2_loss=9.57, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 79.12it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [05:53<00:00, 15.16it/s, ce_loss=5.14, l2_loss=9.54, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 79.06it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [05:53<00:00, 15.15it/s, ce_loss=2.82, l2_loss=9.49, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 79.01it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [05:53<00:00, 15.16it/s, ce_loss=1.31, l2_loss=9.12, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 78.92it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [05:53<00:00, 15.15it/s, ce_loss=0.999, l2_loss=8.3, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 79.16it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [05:53<00:00, 15.14it/s, ce_loss=0.809, l2_loss=7.52, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 78.91it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [05:53<00:00, 15.14it/s, ce_loss=0.873, l2_loss=6.9, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 79.19it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:08<00:00, 79.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 2/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 2\n",
      "- Hidden dimension: 16\n",
      "- Number of heads: 2\n",
      "- Sequence length: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [08:22<00:00, 10.66it/s, ce_loss=9.2, l2_loss=9.63, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:17<00:00, 39.15it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [08:22<00:00, 10.65it/s, ce_loss=7.09, l2_loss=9.64, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:16<00:00, 39.34it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [08:22<00:00, 10.65it/s, ce_loss=4.68, l2_loss=9.65, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:17<00:00, 39.29it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [08:22<00:00, 10.65it/s, ce_loss=2.15, l2_loss=9.66, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:16<00:00, 39.32it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [08:22<00:00, 10.65it/s, ce_loss=0.834, l2_loss=9.25, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:16<00:00, 39.31it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [08:22<00:00, 10.65it/s, ce_loss=0.582, l2_loss=8.36, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:16<00:00, 39.31it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [08:22<00:00, 10.65it/s, ce_loss=0.562, l2_loss=7.53, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:16<00:00, 39.32it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [08:22<00:00, 10.64it/s, ce_loss=0.521, l2_loss=6.85, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:17<00:00, 39.20it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:17<00:00, 39.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 3/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 2\n",
      "- Hidden dimension: 16\n",
      "- Number of heads: 4\n",
      "- Sequence length: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [06:02<00:00, 14.76it/s, ce_loss=9.22, l2_loss=9.62, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 76.54it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [06:02<00:00, 14.76it/s, ce_loss=7.24, l2_loss=9.6, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 76.56it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [06:02<00:00, 14.75it/s, ce_loss=4.97, l2_loss=9.57, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 76.55it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [06:02<00:00, 14.75it/s, ce_loss=2.68, l2_loss=9.51, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 76.40it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [06:02<00:00, 14.75it/s, ce_loss=1.34, l2_loss=9.09, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 76.33it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [06:02<00:00, 14.75it/s, ce_loss=0.946, l2_loss=8.25, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 76.55it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [06:03<00:00, 14.75it/s, ce_loss=0.931, l2_loss=7.48, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 76.74it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [06:03<00:00, 14.74it/s, ce_loss=0.601, l2_loss=6.9, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 76.51it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:08<00:00, 76.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 4/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 2\n",
      "- Hidden dimension: 16\n",
      "- Number of heads: 4\n",
      "- Sequence length: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [09:30<00:00,  9.39it/s, ce_loss=9.24, l2_loss=9.63, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 36.57it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [09:30<00:00,  9.38it/s, ce_loss=7.18, l2_loss=9.64, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 36.63it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [09:30<00:00,  9.38it/s, ce_loss=4.79, l2_loss=9.65, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 36.66it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [09:31<00:00,  9.37it/s, ce_loss=2.23, l2_loss=9.65, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 36.60it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [09:31<00:00,  9.37it/s, ce_loss=0.849, l2_loss=9.29, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 36.60it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [09:31<00:00,  9.36it/s, ce_loss=0.628, l2_loss=8.41, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 36.61it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [09:31<00:00,  9.36it/s, ce_loss=0.464, l2_loss=7.59, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 36.56it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [09:31<00:00,  9.36it/s, ce_loss=0.431, l2_loss=6.92, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 36.60it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:18<00:00, 36.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 5/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 2\n",
      "- Hidden dimension: 32\n",
      "- Number of heads: 2\n",
      "- Sequence length: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [06:36<00:00, 13.50it/s, ce_loss=7.52, l2_loss=13.7, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 77.67it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [06:36<00:00, 13.50it/s, ce_loss=3.68, l2_loss=13.5, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 77.76it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [06:36<00:00, 13.50it/s, ce_loss=0.912, l2_loss=13, lr=1e-5]  \n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 77.79it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [06:36<00:00, 13.49it/s, ce_loss=0.781, l2_loss=11.8, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 78.13it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [06:36<00:00, 13.48it/s, ce_loss=0.674, l2_loss=10.8, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 77.95it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [06:36<00:00, 13.49it/s, ce_loss=0.629, l2_loss=10.1, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 77.78it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [06:36<00:00, 13.49it/s, ce_loss=0.42, l2_loss=9.55, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 77.66it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [06:36<00:00, 13.48it/s, ce_loss=0.484, l2_loss=9.05, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 77.95it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:08<00:00, 78.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 6/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 2\n",
      "- Hidden dimension: 32\n",
      "- Number of heads: 2\n",
      "- Sequence length: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [10:54<00:00,  8.18it/s, ce_loss=7.44, l2_loss=13.6, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:17<00:00, 39.29it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [10:54<00:00,  8.18it/s, ce_loss=3.33, l2_loss=13.6, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:17<00:00, 39.29it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [10:54<00:00,  8.18it/s, ce_loss=0.64, l2_loss=13.1, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:17<00:00, 39.19it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [10:56<00:00,  8.16it/s, ce_loss=0.516, l2_loss=11.8, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:17<00:00, 39.13it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [10:56<00:00,  8.15it/s, ce_loss=0.427, l2_loss=10.7, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:17<00:00, 39.16it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [10:56<00:00,  8.16it/s, ce_loss=0.385, l2_loss=10, lr=1e-5]  \n",
      "Validation: 100%|██████████| 668/668 [00:17<00:00, 39.18it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [10:56<00:00,  8.16it/s, ce_loss=0.368, l2_loss=9.44, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:17<00:00, 39.18it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [10:56<00:00,  8.16it/s, ce_loss=0.378, l2_loss=8.97, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:17<00:00, 39.22it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:17<00:00, 39.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 7/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 2\n",
      "- Hidden dimension: 32\n",
      "- Number of heads: 4\n",
      "- Sequence length: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [06:51<00:00, 13.01it/s, ce_loss=7.56, l2_loss=13.7, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 75.79it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [06:51<00:00, 13.01it/s, ce_loss=3.84, l2_loss=13.5, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 75.55it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [06:51<00:00, 13.01it/s, ce_loss=1.06, l2_loss=13, lr=1e-5]   \n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 75.70it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [06:51<00:00, 13.00it/s, ce_loss=0.872, l2_loss=11.8, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 75.55it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [06:51<00:00, 13.00it/s, ce_loss=0.843, l2_loss=10.8, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 75.69it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [06:51<00:00, 13.00it/s, ce_loss=0.68, l2_loss=10.1, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 75.60it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [06:51<00:00, 13.00it/s, ce_loss=0.671, l2_loss=9.56, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 75.66it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [06:51<00:00, 13.00it/s, ce_loss=0.633, l2_loss=9.06, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:08<00:00, 75.54it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:08<00:00, 75.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 8/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 2\n",
      "- Hidden dimension: 32\n",
      "- Number of heads: 4\n",
      "- Sequence length: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [11:58<00:00,  7.45it/s, ce_loss=7.32, l2_loss=13.7, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 36.57it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [11:59<00:00,  7.44it/s, ce_loss=3.13, l2_loss=13.6, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 36.65it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [12:01<00:00,  7.42it/s, ce_loss=0.639, l2_loss=13.1, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 36.66it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [11:58<00:00,  7.45it/s, ce_loss=0.542, l2_loss=11.8, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 36.62it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [12:02<00:00,  7.41it/s, ce_loss=0.395, l2_loss=10.7, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 36.59it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [12:02<00:00,  7.41it/s, ce_loss=0.26, l2_loss=10, lr=1e-5]   \n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 36.61it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [12:02<00:00,  7.41it/s, ce_loss=0.291, l2_loss=9.46, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 36.67it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [12:01<00:00,  7.42it/s, ce_loss=0.246, l2_loss=8.98, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 36.67it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:18<00:00, 36.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 9/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 2\n",
      "- Hidden dimension: 64\n",
      "- Number of heads: 2\n",
      "- Sequence length: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [09:49<00:00,  9.08it/s, ce_loss=4.33, l2_loss=19.2, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 69.23it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [09:49<00:00,  9.08it/s, ce_loss=0.854, l2_loss=18.1, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 69.49it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [09:49<00:00,  9.08it/s, ce_loss=0.645, l2_loss=16.4, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 69.37it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [09:49<00:00,  9.08it/s, ce_loss=0.528, l2_loss=15.5, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 69.44it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [09:49<00:00,  9.08it/s, ce_loss=0.701, l2_loss=14.7, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 69.48it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [09:49<00:00,  9.08it/s, ce_loss=0.47, l2_loss=14, lr=1e-5]   \n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 69.53it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [09:49<00:00,  9.08it/s, ce_loss=0.43, l2_loss=13.3, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 69.57it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [09:49<00:00,  9.08it/s, ce_loss=0.578, l2_loss=12.6, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 69.51it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:09<00:00, 69.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 10/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 2\n",
      "- Hidden dimension: 64\n",
      "- Number of heads: 2\n",
      "- Sequence length: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [19:02<00:00,  4.68it/s, ce_loss=3.77, l2_loss=19.3, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:19<00:00, 34.80it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [19:03<00:00,  4.68it/s, ce_loss=0.466, l2_loss=18.1, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:19<00:00, 34.82it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [19:03<00:00,  4.68it/s, ce_loss=0.386, l2_loss=16.3, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:19<00:00, 34.77it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [19:03<00:00,  4.68it/s, ce_loss=0.268, l2_loss=15.3, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:19<00:00, 34.80it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [19:03<00:00,  4.68it/s, ce_loss=0.272, l2_loss=14.6, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:19<00:00, 34.85it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [19:03<00:00,  4.68it/s, ce_loss=0.235, l2_loss=13.9, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:19<00:00, 34.83it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [19:03<00:00,  4.68it/s, ce_loss=0.181, l2_loss=13.2, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:19<00:00, 34.83it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [19:03<00:00,  4.68it/s, ce_loss=0.327, l2_loss=12.6, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:19<00:00, 34.87it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:19<00:00, 34.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 11/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 2\n",
      "- Hidden dimension: 64\n",
      "- Number of heads: 4\n",
      "- Sequence length: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [10:06<00:00,  8.82it/s, ce_loss=4.21, l2_loss=19.3, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 67.48it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [10:06<00:00,  8.83it/s, ce_loss=0.847, l2_loss=18.1, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 67.47it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [10:06<00:00,  8.83it/s, ce_loss=0.703, l2_loss=16.4, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 67.48it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [10:06<00:00,  8.83it/s, ce_loss=0.586, l2_loss=15.4, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 67.56it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [10:06<00:00,  8.82it/s, ce_loss=0.629, l2_loss=14.7, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 67.63it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [10:07<00:00,  8.81it/s, ce_loss=0.428, l2_loss=14, lr=1e-5]  \n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 67.54it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [10:06<00:00,  8.83it/s, ce_loss=0.602, l2_loss=13.3, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 67.57it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [10:06<00:00,  8.82it/s, ce_loss=0.457, l2_loss=12.6, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 67.49it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:09<00:00, 67.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 12/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 2\n",
      "- Hidden dimension: 64\n",
      "- Number of heads: 4\n",
      "- Sequence length: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [20:10<00:00,  4.42it/s, ce_loss=3.9, l2_loss=19.3, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:20<00:00, 32.77it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [20:10<00:00,  4.42it/s, ce_loss=0.464, l2_loss=18.1, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:20<00:00, 32.79it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [20:10<00:00,  4.42it/s, ce_loss=0.393, l2_loss=16.4, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:20<00:00, 32.74it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [20:10<00:00,  4.42it/s, ce_loss=0.206, l2_loss=15.4, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:20<00:00, 32.78it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [20:10<00:00,  4.42it/s, ce_loss=0.212, l2_loss=14.6, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:20<00:00, 32.77it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [20:10<00:00,  4.42it/s, ce_loss=0.262, l2_loss=13.9, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:20<00:00, 32.76it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [20:10<00:00,  4.42it/s, ce_loss=0.246, l2_loss=13.2, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:20<00:00, 32.77it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [20:10<00:00,  4.42it/s, ce_loss=0.271, l2_loss=12.6, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:20<00:00, 32.80it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:20<00:00, 32.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 13/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 4\n",
      "- Hidden dimension: 16\n",
      "- Number of heads: 2\n",
      "- Sequence length: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [06:39<00:00, 13.41it/s, ce_loss=9.23, l2_loss=10.2, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 72.11it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [06:38<00:00, 13.43it/s, ce_loss=7.24, l2_loss=10.1, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 72.15it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [06:38<00:00, 13.43it/s, ce_loss=5.05, l2_loss=9.96, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 71.94it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [06:38<00:00, 13.43it/s, ce_loss=2.66, l2_loss=9.82, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 72.10it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [06:38<00:00, 13.42it/s, ce_loss=1.1, l2_loss=9.34, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 71.95it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [06:38<00:00, 13.42it/s, ce_loss=1.09, l2_loss=8.45, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 72.14it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [06:38<00:00, 13.42it/s, ce_loss=0.993, l2_loss=7.63, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 71.98it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [06:38<00:00, 13.42it/s, ce_loss=0.846, l2_loss=7.02, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 71.95it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:09<00:00, 71.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 14/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 4\n",
      "- Hidden dimension: 16\n",
      "- Number of heads: 2\n",
      "- Sequence length: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [10:04<00:00,  8.86it/s, ce_loss=9.16, l2_loss=10.2, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 35.49it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [10:04<00:00,  8.85it/s, ce_loss=7.03, l2_loss=10.1, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 35.61it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [10:05<00:00,  8.85it/s, ce_loss=4.61, l2_loss=10.1, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 35.62it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [10:05<00:00,  8.85it/s, ce_loss=2.05, l2_loss=9.98, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 35.59it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [10:05<00:00,  8.85it/s, ce_loss=0.791, l2_loss=9.47, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 35.65it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [10:05<00:00,  8.84it/s, ce_loss=0.592, l2_loss=8.52, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 35.62it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [10:05<00:00,  8.84it/s, ce_loss=0.526, l2_loss=7.66, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 35.61it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [10:05<00:00,  8.84it/s, ce_loss=0.495, l2_loss=6.96, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 35.58it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:18<00:00, 35.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 15/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 4\n",
      "- Hidden dimension: 16\n",
      "- Number of heads: 4\n",
      "- Sequence length: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [06:59<00:00, 12.76it/s, ce_loss=9.26, l2_loss=10.2, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 68.05it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [06:59<00:00, 12.75it/s, ce_loss=7.28, l2_loss=10.1, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 67.79it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [06:59<00:00, 12.75it/s, ce_loss=5.05, l2_loss=9.97, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 68.01it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [06:59<00:00, 12.75it/s, ce_loss=2.74, l2_loss=9.83, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 67.92it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [06:59<00:00, 12.75it/s, ce_loss=1.2, l2_loss=9.35, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 67.76it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [06:59<00:00, 12.75it/s, ce_loss=0.826, l2_loss=8.45, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 67.95it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [07:00<00:00, 12.74it/s, ce_loss=0.952, l2_loss=7.63, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 67.81it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [07:00<00:00, 12.74it/s, ce_loss=0.876, l2_loss=7.02, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 67.92it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:09<00:00, 67.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 16/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 4\n",
      "- Hidden dimension: 16\n",
      "- Number of heads: 4\n",
      "- Sequence length: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [12:18<00:00,  7.25it/s, ce_loss=9.14, l2_loss=10.2, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.36it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [12:22<00:00,  7.21it/s, ce_loss=7.01, l2_loss=10.1, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.43it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [12:22<00:00,  7.21it/s, ce_loss=4.56, l2_loss=10, lr=1e-5]  \n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.37it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [12:23<00:00,  7.20it/s, ce_loss=2.04, l2_loss=9.95, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.37it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [12:23<00:00,  7.20it/s, ce_loss=0.834, l2_loss=9.44, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.34it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [12:24<00:00,  7.19it/s, ce_loss=0.609, l2_loss=8.5, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.36it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [12:24<00:00,  7.19it/s, ce_loss=0.581, l2_loss=7.65, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.33it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [12:24<00:00,  7.19it/s, ce_loss=0.468, l2_loss=6.96, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.36it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:21<00:00, 31.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 17/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 4\n",
      "- Hidden dimension: 32\n",
      "- Number of heads: 2\n",
      "- Sequence length: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [07:28<00:00, 11.93it/s, ce_loss=7.62, l2_loss=14.4, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 70.47it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [07:28<00:00, 11.93it/s, ce_loss=3.96, l2_loss=14.1, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 70.27it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [07:28<00:00, 11.93it/s, ce_loss=1.07, l2_loss=13.4, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 70.34it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [07:28<00:00, 11.93it/s, ce_loss=0.915, l2_loss=12, lr=1e-5]  \n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 70.56it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [07:28<00:00, 11.92it/s, ce_loss=0.794, l2_loss=11, lr=1e-5]  \n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 70.39it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [07:28<00:00, 11.92it/s, ce_loss=0.726, l2_loss=10.3, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 70.04it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [07:29<00:00, 11.92it/s, ce_loss=0.771, l2_loss=9.69, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 70.35it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [07:29<00:00, 11.92it/s, ce_loss=0.583, l2_loss=9.18, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:09<00:00, 70.26it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:09<00:00, 70.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 18/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 4\n",
      "- Hidden dimension: 32\n",
      "- Number of heads: 2\n",
      "- Sequence length: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [12:42<00:00,  7.02it/s, ce_loss=7.27, l2_loss=14.5, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:19<00:00, 35.11it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [12:42<00:00,  7.02it/s, ce_loss=3.21, l2_loss=14.2, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 35.17it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [12:42<00:00,  7.02it/s, ce_loss=0.701, l2_loss=13.5, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:19<00:00, 35.15it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [12:43<00:00,  7.02it/s, ce_loss=0.566, l2_loss=12, lr=1e-5]  \n",
      "Validation: 100%|██████████| 668/668 [00:19<00:00, 35.14it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [12:42<00:00,  7.02it/s, ce_loss=0.471, l2_loss=10.9, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 35.16it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [12:42<00:00,  7.02it/s, ce_loss=0.403, l2_loss=10.2, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:19<00:00, 35.15it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [12:43<00:00,  7.02it/s, ce_loss=0.409, l2_loss=9.6, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:19<00:00, 35.14it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [12:42<00:00,  7.02it/s, ce_loss=0.309, l2_loss=9.13, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:18<00:00, 35.20it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:19<00:00, 35.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 19/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 4\n",
      "- Hidden dimension: 32\n",
      "- Number of heads: 4\n",
      "- Sequence length: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [08:00<00:00, 11.13it/s, ce_loss=7.48, l2_loss=14.4, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:10<00:00, 66.74it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [08:01<00:00, 11.13it/s, ce_loss=3.79, l2_loss=14.1, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:10<00:00, 66.71it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [08:01<00:00, 11.12it/s, ce_loss=0.981, l2_loss=13.4, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:10<00:00, 66.54it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [08:03<00:00, 11.08it/s, ce_loss=1, l2_loss=12, lr=1e-5]      \n",
      "Validation: 100%|██████████| 668/668 [00:10<00:00, 66.44it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [08:03<00:00, 11.08it/s, ce_loss=0.827, l2_loss=11, lr=1e-5]  \n",
      "Validation: 100%|██████████| 668/668 [00:10<00:00, 66.35it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [08:03<00:00, 11.08it/s, ce_loss=0.717, l2_loss=10.3, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:10<00:00, 66.39it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [08:03<00:00, 11.07it/s, ce_loss=0.601, l2_loss=9.69, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:10<00:00, 66.61it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [08:03<00:00, 11.07it/s, ce_loss=0.68, l2_loss=9.19, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:10<00:00, 66.57it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:10<00:00, 66.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 20/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 4\n",
      "- Hidden dimension: 32\n",
      "- Number of heads: 4\n",
      "- Sequence length: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [14:58<00:00,  5.96it/s, ce_loss=7.3, l2_loss=14.5, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.07it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [14:59<00:00,  5.95it/s, ce_loss=3.18, l2_loss=14.2, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.16it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [14:59<00:00,  5.95it/s, ce_loss=0.634, l2_loss=13.5, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.16it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [14:59<00:00,  5.95it/s, ce_loss=0.518, l2_loss=12, lr=1e-5]  \n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.10it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [14:59<00:00,  5.95it/s, ce_loss=0.503, l2_loss=10.9, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.13it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [14:59<00:00,  5.95it/s, ce_loss=0.415, l2_loss=10.2, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.13it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [15:00<00:00,  5.95it/s, ce_loss=0.315, l2_loss=9.6, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.19it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [14:59<00:00,  5.95it/s, ce_loss=0.264, l2_loss=9.13, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.16it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:21<00:00, 31.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 21/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 4\n",
      "- Hidden dimension: 64\n",
      "- Number of heads: 2\n",
      "- Sequence length: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [10:50<00:00,  8.23it/s, ce_loss=4.16, l2_loss=20.3, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:10<00:00, 62.43it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [10:49<00:00,  8.24it/s, ce_loss=0.798, l2_loss=18.6, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:10<00:00, 62.54it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [10:49<00:00,  8.24it/s, ce_loss=0.729, l2_loss=16.8, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:10<00:00, 62.52it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [10:49<00:00,  8.24it/s, ce_loss=0.633, l2_loss=15.7, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:10<00:00, 62.44it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [10:50<00:00,  8.23it/s, ce_loss=0.515, l2_loss=14.9, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:10<00:00, 62.57it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [10:50<00:00,  8.23it/s, ce_loss=0.535, l2_loss=14.2, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:10<00:00, 62.57it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [10:50<00:00,  8.23it/s, ce_loss=0.679, l2_loss=13.5, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:10<00:00, 62.61it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [10:51<00:00,  8.22it/s, ce_loss=0.639, l2_loss=12.8, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:10<00:00, 62.50it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:10<00:00, 62.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 22/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 4\n",
      "- Hidden dimension: 64\n",
      "- Number of heads: 2\n",
      "- Sequence length: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [21:07<00:00,  4.22it/s, ce_loss=3.72, l2_loss=20.3, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.02it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [21:07<00:00,  4.22it/s, ce_loss=0.488, l2_loss=18.5, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.03it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [21:07<00:00,  4.22it/s, ce_loss=0.43, l2_loss=16.6, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.04it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [21:08<00:00,  4.22it/s, ce_loss=0.327, l2_loss=15.6, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.01it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [21:08<00:00,  4.22it/s, ce_loss=0.324, l2_loss=14.8, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.01it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [21:08<00:00,  4.22it/s, ce_loss=0.269, l2_loss=14.1, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.08it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [21:07<00:00,  4.22it/s, ce_loss=0.282, l2_loss=13.4, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.07it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [21:07<00:00,  4.22it/s, ce_loss=0.254, l2_loss=12.8, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:21<00:00, 31.09it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:21<00:00, 31.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 23/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 4\n",
      "- Hidden dimension: 64\n",
      "- Number of heads: 4\n",
      "- Sequence length: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [11:22<00:00,  7.84it/s, ce_loss=4.18, l2_loss=20.3, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:11<00:00, 59.43it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [11:22<00:00,  7.84it/s, ce_loss=0.909, l2_loss=18.6, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:11<00:00, 59.64it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [11:22<00:00,  7.84it/s, ce_loss=0.74, l2_loss=16.8, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:11<00:00, 59.57it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [11:23<00:00,  7.84it/s, ce_loss=0.588, l2_loss=15.7, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:11<00:00, 59.66it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [11:23<00:00,  7.83it/s, ce_loss=0.373, l2_loss=14.9, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:11<00:00, 59.73it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [11:23<00:00,  7.83it/s, ce_loss=0.627, l2_loss=14.2, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:11<00:00, 59.59it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [11:23<00:00,  7.83it/s, ce_loss=0.483, l2_loss=13.5, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:11<00:00, 59.69it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [11:23<00:00,  7.83it/s, ce_loss=0.442, l2_loss=12.8, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:11<00:00, 59.60it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:11<00:00, 59.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 24/24\n",
      "Current parameters being tested:\n",
      "- Number of layers: 4\n",
      "- Hidden dimension: 64\n",
      "- Number of heads: 4\n",
      "- Sequence length: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 5353/5353 [23:20<00:00,  3.82it/s, ce_loss=3.7, l2_loss=20.4, lr=1e-5] \n",
      "Validation: 100%|██████████| 668/668 [00:23<00:00, 27.90it/s]\n",
      "Epoch 2/8: 100%|██████████| 5353/5353 [23:20<00:00,  3.82it/s, ce_loss=0.604, l2_loss=18.6, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:23<00:00, 27.90it/s]\n",
      "Epoch 3/8: 100%|██████████| 5353/5353 [23:20<00:00,  3.82it/s, ce_loss=0.456, l2_loss=16.6, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:23<00:00, 27.92it/s]\n",
      "Epoch 4/8: 100%|██████████| 5353/5353 [23:20<00:00,  3.82it/s, ce_loss=0.367, l2_loss=15.6, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:23<00:00, 27.91it/s]\n",
      "Epoch 5/8: 100%|██████████| 5353/5353 [23:20<00:00,  3.82it/s, ce_loss=0.305, l2_loss=14.8, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:23<00:00, 27.90it/s]\n",
      "Epoch 6/8: 100%|██████████| 5353/5353 [23:20<00:00,  3.82it/s, ce_loss=0.339, l2_loss=14.1, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:23<00:00, 27.93it/s]\n",
      "Epoch 7/8: 100%|██████████| 5353/5353 [23:20<00:00,  3.82it/s, ce_loss=0.288, l2_loss=13.4, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:23<00:00, 27.93it/s]\n",
      "Epoch 8/8: 100%|██████████| 5353/5353 [23:20<00:00,  3.82it/s, ce_loss=0.261, l2_loss=12.8, lr=1e-5]\n",
      "Validation: 100%|██████████| 668/668 [00:23<00:00, 27.93it/s]\n",
      "Testing: 100%|██████████| 670/670 [00:24<00:00, 27.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Hyperparameters:\n",
      "Layers: 2\n",
      "Hidden Dimension: 64\n",
      "Number of Heads: 4\n",
      "Sequence Length: 512\n",
      "Key/Query Dimension (d_k): 16\n",
      "Test Perplexity: 1.3115\n",
      "\n",
      "Experiment completed!\n",
      "Best model saved to: experiments/experiment_20241112_163001/best_best_model.pt\n",
      "Full logs saved to: experiments/experiment_20241112_163001/experiment_log.pdf\n",
      "Results saved to: experiments/experiment_20241112_163001/experiment_results.json\n"
     ]
    }
   ],
   "source": [
    "hidden_dims = [16, 32, 64] # Hidden dimensions\n",
    "hidden_layers = [2, 4] # Hidden layers\n",
    "n_heads_list = [2, 4] # Number of heads\n",
    "seq_length = [256, 512] # Sequence length\n",
    "\n",
    "best_model_path = experiment_tracker( # Experiment tracker\n",
    "    hidden_dims=hidden_dims, # Hidden dimensions\n",
    "    hidden_layers=hidden_layers, # Hidden layers\n",
    "    n_heads_list=n_heads_list, # Number of heads\n",
    "    seq_length=seq_length) # Sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Se1bb_1TQ7sD"
   },
   "outputs": [],
   "source": [
    "# clear the torch cache\n",
    "\n",
    "torch.cuda.empty_cache() # Clear CUDA cache\n",
    "gc.collect() # Garbage collect\n",
    "torch.cuda.empty_cache() # Clear CUDA cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 38
    },
    "id": "FV38ve3kAi8Q",
    "outputId": "415db887-d2e5-4160-dc2a-05315990ba45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments/experiment_20241112_163001/best_best_model.pt'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdCYLszyQ7sE"
   },
   "source": [
    "### Best Model Hyperparameters:\n",
    "\n",
    "Layers: 2\n",
    "\n",
    "Hidden Dimension: 64\n",
    "\n",
    "Number of Heads: 4\n",
    "\n",
    "Sequence Length: 512\n",
    "\n",
    "Key/Query Dimension (d_k): 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "8dG-CP_JQ7sE"
   },
   "outputs": [],
   "source": [
    "best_model = Decoder(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    max_len=tokenizer.model_max_length,\n",
    "    d_k=16, # Key/Query dimension\n",
    "    d_model=64, # Hidden dimension\n",
    "    n_heads=4, # Number of attention heads\n",
    "    n_layers=2, # Number of transformer layers\n",
    "    dropout_prob=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9H7qQdoQ7sF",
    "outputId": "6c56c8ca-e7da-4e11-a78e-82d510fee1e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if it matches the best model path\n",
    "\n",
    "checkpoint = torch.load(best_model_path)\n",
    "best_model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "Choose any 5 samples from the test dataset and generate the model outputs. (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "8jaa5aAfQ7sF"
   },
   "outputs": [],
   "source": [
    "def custom_generate(\n",
    "    model,\n",
    "    input_ids,\n",
    "    attention_mask,\n",
    "    max_length=1024,\n",
    "    num_return_sequences=3,\n",
    "    temperature=1.0,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2\n",
    "):\n",
    "    \"\"\"\n",
    "    Enhanced text generation function with additional control mechanisms\n",
    "\n",
    "    Args:\n",
    "        model: Pre-trained language model\n",
    "        input_ids: Input token IDs\n",
    "        attention_mask: Attention mask for input tokens\n",
    "        max_length: Maximum generated sequence length\n",
    "        num_return_sequences: Number of alternative sequences to generate\n",
    "        temperature: Controls randomness of prediction\n",
    "        top_k: Number of highest probability tokens to keep\n",
    "        top_p: Nucleus sampling threshold\n",
    "        repetition_penalty: Penalty for repeating tokens\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = input_ids.device\n",
    "    generated_sequences = []\n",
    "    eos_token_id = 50256  # GPT-2 end-of-sequence token\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in range(input_ids.size(0)):\n",
    "            single_input_ids = input_ids[batch_idx:batch_idx+1]\n",
    "            single_attention_mask = attention_mask[batch_idx:batch_idx+1]\n",
    "\n",
    "            batch_sequences = []\n",
    "            for _ in range(num_return_sequences):\n",
    "                current_ids = single_input_ids.clone()\n",
    "                current_mask = single_attention_mask.clone()\n",
    "\n",
    "                generation_attempts = 0\n",
    "                max_generation_attempts = 10\n",
    "\n",
    "                while (current_ids.shape[1] < max_length and\n",
    "                       generation_attempts < max_generation_attempts):\n",
    "                    generation_attempts += 1\n",
    "\n",
    "                    try:\n",
    "                        # Model prediction\n",
    "                        outputs = model(current_ids, current_mask)\n",
    "                        logits = outputs[:, -1, :]\n",
    "\n",
    "                        # Temperature scaling\n",
    "                        logits = logits / temperature\n",
    "\n",
    "                        # Repetition penalty\n",
    "                        if generation_attempts > 1:\n",
    "                            for prev_token in current_ids[0]:\n",
    "                                logits[:, prev_token] /= repetition_penalty\n",
    "\n",
    "                        # Top-k and Top-p filtering\n",
    "                        top_k_values, top_k_indices = torch.topk(logits, min(top_k, logits.size(-1)), dim=-1)\n",
    "\n",
    "                        # Nucleus sampling (Top-p)\n",
    "                        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "                        cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "                        # Remove tokens with cumulative probability above top_p\n",
    "                        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "                        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "                        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "                        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "                        logits[:, indices_to_remove] = float('-inf')\n",
    "\n",
    "                        # Sample next token\n",
    "                        probabilities = torch.softmax(logits, dim=-1)\n",
    "                        probabilities = torch.nan_to_num(probabilities, nan=0.0)\n",
    "                        probabilities = torch.clamp(probabilities, min=0, max=1)\n",
    "                        probabilities /= probabilities.sum(dim=-1, keepdim=True)\n",
    "\n",
    "                        next_token = torch.multinomial(probabilities, num_samples=1)\n",
    "\n",
    "                        # Append token and update masks\n",
    "                        current_ids = torch.cat([current_ids, next_token], dim=-1)\n",
    "                        current_mask = torch.cat([\n",
    "                            current_mask,\n",
    "                            torch.ones_like(next_token, dtype=torch.long)\n",
    "                        ], dim=-1)\n",
    "\n",
    "                        # Stop generation conditions\n",
    "                        if (next_token == eos_token_id).any() or current_ids.shape[1] >= max_length:\n",
    "                            break\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Generation error: {e}\")\n",
    "                        break\n",
    "\n",
    "                batch_sequences.append(current_ids)\n",
    "\n",
    "            generated_sequences.append(torch.cat(batch_sequences, dim=0))\n",
    "\n",
    "    return torch.cat(generated_sequences, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "USoKWMwKQ7sF"
   },
   "outputs": [],
   "source": [
    "best_hyperparameter_model = create_transformer_decoder(\n",
    "    d_k=1,\n",
    "    d_model=4,\n",
    "    n_heads=4,\n",
    "    n_layers=4,\n",
    "    dropout_prob=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embedding): Embedding(50257, 64)\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): CausalSelfAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): CausalSelfAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=64, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_nTjqAU2Q7sF",
    "outputId": "053d77b1-e006-4917-da9b-388019b2eb22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke 1:\n",
      "whats long and hard and full of semen a submarine\n",
      "w h a t s   l o n g   a n d   h a r d   a n d   ! ! ! ! ! ! a r d o n   M e l l l e i g h   a\n",
      "\n",
      "Joke 2:\n",
      "did you hear about the knifewielding madman who attacked a circus camp the other day he went straight for the juggler\n",
      "w h a t s   l o n g   a n d   h a r d   a n d   ! ! ! ! ! P R O   t o   a   t h e   V a r i o u s\n",
      "\n",
      "Joke 3:\n",
      "would you like to make me wine join everyone stomping my grapes\n",
      "w h a t s   l o n g   a n d   h a r d   a n d   ! ! ! ! ! !   M a r i o   t h e   a   A g e\n",
      "\n",
      "Joke 4:\n",
      "yo mamas so fat she fell in love and broke it\n",
      "d i d   y o u   h e a r   a b o u t   t h e   k n i f e w i e l d i n g   m a d m a n   w h o   a t t a c k e d   a   a   t o ! ! ! ! ! C a   t h e   d o\n",
      "\n",
      "Joke 5:\n",
      "i hate the word chicks can we politely call them ladies women please ladies nuts on your chin\n",
      "d i d   y o u   h e a r   a b o u t   t h e   k n i f e w i e l d i n g   m a d m a n   w h o   a t t a c k e d   a   i   a a s   o f   a n d F o r g e M o d L o a d e r   p i o n e e r ! ! !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model.to(device)\n",
    "\n",
    "random.seed(40)\n",
    "test_samples = random.sample(test_jokes, 5)\n",
    "\n",
    "# Split each joke into two halves\n",
    "half_test_samples = [joke[:len(joke)//2] for joke in test_samples]\n",
    "\n",
    "test_samples_tokenized = tokenizer(\n",
    "    half_test_samples,  # Use only the first half of each joke\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=512,  # seq_lengths\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids = test_samples_tokenized['input_ids'].to(device)\n",
    "attention_mask = test_samples_tokenized['attention_mask'].to(device)\n",
    "\n",
    "try:\n",
    "    outputs = custom_generate(\n",
    "        best_model,\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=1024,  # seq_lengths\n",
    "        num_return_sequences=3,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.2\n",
    "    )\n",
    "\n",
    "    generated_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    for i, (joke, continuation) in enumerate(zip(test_samples, generated_texts)):\n",
    "        print(f\"Joke {i+1}:\")   \n",
    "        print(joke)\n",
    "        print(\" \".join(continuation))\n",
    "        print()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Generation error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "ytdxkVG2Q7sF"
   },
   "outputs": [],
   "source": [
    "# Clean up the GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqHtUP42Mlma"
   },
   "source": [
    "## Question 2\n",
    "\n",
    "Finetune a GPT-2 model using the dataset and compare the responses of your model and the finetuned GPT-2 model. (18 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "bqeICgorQ7sF"
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "-k9GUO6tQ7sG"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def calculate_perplexity(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Calculating perplexity\"):\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "\n",
    "            # Get model outputs\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            # Calculate number of tokens in batch (excluding padding)\n",
    "            num_tokens = torch.sum(attention_mask).item()\n",
    "\n",
    "            total_loss += loss.item() * num_tokens\n",
    "            total_tokens += num_tokens\n",
    "\n",
    "    # Calculate perplexity\n",
    "    avg_loss = total_loss / total_tokens\n",
    "    perplexity = math.exp(avg_loss)\n",
    "\n",
    "    # Return both perplexity and average loss\n",
    "    return perplexity, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "pNdHUqdmQ7sG"
   },
   "outputs": [],
   "source": [
    "def finetune_gpt2(tokenized_train, tokenized_val, tokenized_test, test_samples, batch_size=8, epochs=100, patience=3):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    set_seed(42)\n",
    "\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model.to(device)\n",
    "\n",
    "    train_dataset = prepare_data_for_training(tokenized_train, seq_length=128)\n",
    "    val_dataset = prepare_data_for_training(tokenized_val, seq_length=128)\n",
    "    test_dataset = prepare_data_for_training(tokenized_test, seq_length=128)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    print(\"\\nCalculating initial perplexities...\")\n",
    "    initial_train_perplexity, initial_train_loss = calculate_perplexity(model, train_dataloader, device)\n",
    "    initial_val_perplexity, initial_val_loss = calculate_perplexity(model, val_dataloader, device)\n",
    "    initial_test_perplexity, initial_test_loss = calculate_perplexity(model, test_dataloader, device)\n",
    "\n",
    "    print(f\"Initial metrics:\")\n",
    "    print(f\"Train - Loss: {initial_train_loss:.4f}, Perplexity: {initial_train_perplexity:.2f}\")\n",
    "    print(f\"Val   - Loss: {initial_val_loss:.4f}, Perplexity: {initial_val_perplexity:.2f}\")\n",
    "    print(f\"Test  - Loss: {initial_test_loss:.4f}, Perplexity: {initial_test_perplexity:.2f}\")\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "    val_losses = []\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        train_progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "\n",
    "        for batch in train_progress_bar:\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "            loss = outputs.loss\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "        # Calculate epoch metrics\n",
    "        print(\"\\nCalculating epoch metrics...\")\n",
    "        train_perplexity, avg_train_loss = calculate_perplexity(model, train_dataloader, device)\n",
    "        val_perplexity, avg_val_loss = calculate_perplexity(model, val_dataloader, device)\n",
    "        test_perplexity, avg_test_loss = calculate_perplexity(model, test_dataloader, device)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}:\")\n",
    "        print(f\"Train - Loss: {avg_train_loss:.4f}, Perplexity: {train_perplexity:.2f}\")\n",
    "        print(f\"Val   - Loss: {avg_val_loss:.4f}, Perplexity: {val_perplexity:.2f}\")\n",
    "        print(f\"Test  - Loss: {avg_test_loss:.4f}, Perplexity: {test_perplexity:.2f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            early_stopping_counter = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': avg_train_loss,\n",
    "                'train_perplexity': train_perplexity,\n",
    "                'val_loss': avg_val_loss,\n",
    "                'val_perplexity': val_perplexity,\n",
    "                'test_loss': avg_test_loss,\n",
    "                'test_perplexity': test_perplexity\n",
    "            }, 'best_gpt2_model.pt')\n",
    "            print(\"Saved new best model!\")\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            print(f\"Validation loss did not improve. Counter: {early_stopping_counter}/{patience}\")\n",
    "\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # Check if validation loss is continuously increasing\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered! Validation loss hasn't improved for {patience} epochs.\")\n",
    "            break\n",
    "\n",
    "    # Load best model for generation\n",
    "    print(\"\\nLoading best model for generation...\")\n",
    "    checkpoint = torch.load('best_gpt2_model.pt')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    print(f\"\\nBest model metrics (from epoch {checkpoint['epoch']+1}):\")\n",
    "    print(f\"Train - Loss: {checkpoint['train_loss']:.4f}, Perplexity: {checkpoint['train_perplexity']:.2f}\")\n",
    "    print(f\"Val   - Loss: {checkpoint['val_loss']:.4f}, Perplexity: {checkpoint['val_perplexity']:.2f}\")\n",
    "    print(f\"Test  - Loss: {checkpoint['test_loss']:.4f}, Perplexity: {checkpoint['test_perplexity']:.2f}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Generate text for half of test samples\n",
    "    print(\"\\nGenerating text for test samples...\")\n",
    "    test_samples_subset = test_samples[:len(test_samples)//2]\n",
    "    generated_outputs = []\n",
    "\n",
    "    for sample in tqdm(test_samples_subset):\n",
    "        encoded_input = tokenizer.encode(sample, return_tensors='pt').to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                encoded_input,\n",
    "                max_length=150,\n",
    "                num_return_sequences=1,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                no_repeat_ngram_size=2,\n",
    "                do_sample=True,\n",
    "                top_k=50,\n",
    "                top_p=0.95,\n",
    "                temperature=0.7\n",
    "            )\n",
    "\n",
    "        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        generated_outputs.append(generated_text)\n",
    "\n",
    "    # Print original and generated texts\n",
    "    print(\"\\nOriginal vs Generated Texts:\")\n",
    "    for original, generated in zip(test_samples_subset, generated_outputs):\n",
    "        print(\"\\nOriginal:\", original)\n",
    "        print(\"Generated:\", generated)\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    return model, generated_outputs, checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lw-hup3RQ7sG",
    "outputId": "a4336c7c-01a2-44f1-9f5f-69b120fd4bdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating initial perplexities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 5353/5353 [08:44<00:00, 10.21it/s]\n",
      "Calculating perplexity: 100%|██████████| 668/668 [01:05<00:00, 10.21it/s]\n",
      "Calculating perplexity: 100%|██████████| 670/670 [01:05<00:00, 10.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial metrics:\n",
      "Train - Loss: 7.5942, Perplexity: 1986.72\n",
      "Val   - Loss: 7.5886, Perplexity: 1975.57\n",
      "Test  - Loss: 7.5776, Perplexity: 1953.98\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 5353/5353 [30:25<00:00,  2.93it/s, loss=0.511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating epoch metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 5353/5353 [08:44<00:00, 10.20it/s]\n",
      "Calculating perplexity: 100%|██████████| 668/668 [01:05<00:00, 10.20it/s]\n",
      "Calculating perplexity: 100%|██████████| 670/670 [01:05<00:00, 10.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:\n",
      "Train - Loss: 0.5121, Perplexity: 1.67\n",
      "Val   - Loss: 0.5383, Perplexity: 1.71\n",
      "Test  - Loss: 0.5211, Perplexity: 1.68\n",
      "Saved new best model!\n",
      "\n",
      "Loading best model for generation...\n",
      "\n",
      "Best model metrics (from epoch 1):\n",
      "Train - Loss: 0.5121, Perplexity: 1.67\n",
      "Val   - Loss: 0.5383, Perplexity: 1.71\n",
      "Test  - Loss: 0.5211, Perplexity: 1.68\n",
      "\n",
      "Generating text for test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "100%|██████████| 2/2 [00:00<00:00, 71.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original vs Generated Texts:\n",
      "\n",
      "Original: whats long and hard and full of semen a submarine\n",
      "Generated: whats long and hard and full of semen a submarine\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Original: did you hear about the knifewielding madman who attacked a circus camp the other day he went straight for the juggler\n",
      "Generated: did you hear about the knifewielding madman who attacked a circus camp the other day he went straight for the juggler\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model, outputs, best_checkpoint = finetune_gpt2(\n",
    "        tokenized_train,\n",
    "        tokenized_val,\n",
    "        tokenized_test,\n",
    "        test_samples,\n",
    "        batch_size=8,\n",
    "        epochs=1,\n",
    "        patience=1  # Number of epochs to wait before early stopping\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating text for test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 31.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original vs Generated Texts:\n",
      "\n",
      "Original: meteorologists people who tell something wrong and still get paid\n",
      "Generated: meteorologists people who tell something wrong and still get paid a little more than someone who only knows about it\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Original: tifu by not having a picture of my pet ready on my cake day what were you expecting to see here\n",
      "Generated: tifu by not having a picture of my pet ready on my cake day what were you expecting to see here the next day\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Original: whats the best part about having a deaf child you can have sex as loudly as you want\n",
      "Generated: whats the best part about having a deaf child you can have sex as loudly as you want\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Original: scottish independence\n",
      "Generated: scottish independence\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Original: a muslim tried to tell a joke it bombed\n",
      "Generated: a muslim tried to tell a joke it bombed my room\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_from_samples(model, tokenizer, test_samples, num_samples=5, device=None):\n",
    "    \"\"\"\n",
    "    Generate text using a fine-tuned GPT-2 model for random test samples.\n",
    "    \n",
    "    Args:\n",
    "        model: Fine-tuned GPT-2 model\n",
    "        tokenizer: GPT-2 tokenizer\n",
    "        test_samples: List of all test samples\n",
    "        num_samples: Number of random samples to use\n",
    "        device: Torch device (cuda/cpu)\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Randomly select samples\n",
    "    random.seed(42)\n",
    "    selected_samples = random.sample(test_samples, num_samples)\n",
    "    generated_outputs = []\n",
    "    \n",
    "    print(\"\\nGenerating text for test samples...\")\n",
    "    for sample in tqdm(selected_samples):\n",
    "        encoded_input = tokenizer.encode(sample, return_tensors='pt').to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                encoded_input,\n",
    "                max_length=150,\n",
    "                num_return_sequences=1,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                no_repeat_ngram_size=2,\n",
    "                do_sample=True,\n",
    "                top_k=50,\n",
    "                top_p=0.95,\n",
    "                temperature=0.7\n",
    "            )\n",
    "        \n",
    "        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        generated_outputs.append(generated_text)\n",
    "    \n",
    "    # Print original and generated texts\n",
    "    print(\"\\nOriginal vs Generated Texts:\")\n",
    "    for original, generated in zip(selected_samples, generated_outputs):\n",
    "        print(\"\\nOriginal:\", original)\n",
    "        print(\"Generated:\", generated)\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    return generated_outputs\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the saved model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Initialize model and tokenizer\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    \n",
    "    # Load the saved checkpoint\n",
    "    checkpoint = torch.load('best_gpt2_model.pt')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Generate text for 5 random samples\n",
    "    generated_texts = generate_from_samples(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        test_samples=test_samples,  # Assuming test_samples is defined\n",
    "        num_samples=5,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_samples(model, tokenizer, test_samples, num_samples=5, device=None):\n",
    "    \"\"\"\n",
    "    Generate text using a fine-tuned GPT-2 model for random test samples.\n",
    "    Uses the first half of each sample as input and generates the continuation.\n",
    "    \n",
    "    Args:\n",
    "        model: Fine-tuned GPT-2 model\n",
    "        tokenizer: GPT-2 tokenizer\n",
    "        test_samples: List of all test samples\n",
    "        num_samples: Number of random samples to use\n",
    "        device: Torch device (cuda/cpu)\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Randomly select samples\n",
    "    random.seed(42)\n",
    "    selected_samples = random.sample(test_samples, num_samples)\n",
    "    \n",
    "    # Take first half of each sample\n",
    "    half_samples = [sample[:len(sample)//2] for sample in selected_samples]\n",
    "    generated_outputs = []\n",
    "    \n",
    "    print(\"\\nGenerating text for test samples...\")\n",
    "    for half_sample in tqdm(half_samples):\n",
    "        encoded_input = tokenizer.encode(half_sample, return_tensors='pt').to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                encoded_input,\n",
    "                max_length=150,\n",
    "                num_return_sequences=1,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                no_repeat_ngram_size=2,\n",
    "                do_sample=True,\n",
    "                top_k=50,\n",
    "                top_p=0.95,\n",
    "                temperature=0.7\n",
    "            )\n",
    "        \n",
    "        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        generated_outputs.append(generated_text)\n",
    "    \n",
    "    # Print original, half sample, and generated texts\n",
    "    print(\"\\nOriginal vs Generated Texts:\")\n",
    "    for original, half, generated in zip(selected_samples, half_samples, generated_outputs):\n",
    "        print(\"\\nOriginal full text:\", original)\n",
    "        print(\"Input (first half):\", half)\n",
    "        print(\"Generated continuation:\", generated)\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    return generated_outputs\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the saved model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Initialize model and tokenizer\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    \n",
    "    # Load the saved checkpoint\n",
    "    checkpoint = torch.load('best_gpt2_model.pt')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Generate text for 5 random samples\n",
    "    generated_texts = generate_from_samples(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        test_samples=test_samples,  # Assuming test_samples is defined\n",
    "        num_samples=5,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs\n",
    "# Original vs Generated Texts:\n",
    "# \n",
    "# Original full text: what happens when someone spills really hot coffee on you you will get burned you idiot\n",
    "# Input (first half): what happens when someone spills really hot\n",
    "# Generated continuation: what happens when someone spills really hot water you cant even\n",
    "# --------------------------------------------------------------------------------\n",
    "# \n",
    "# Original full text: what saudi funded event ended in a massive collapse on 911 hillary clintons campaign\n",
    "# Input (first half): what saudi funded event ended in a massive\n",
    "# Generated continuation: what saudi funded event ended in a massive earthquake i dont know what theres but a lot of people there\n",
    "# --------------------------------------------------------------------------------\n",
    "# \n",
    "# Original full text: the bad zoo a man walks into a zoo the only animal in the zoo is a dog its a shizhu\n",
    "# Input (first half): the bad zoo a man walks into a zoo the on\n",
    "# Generated continuation: the bad zoo a man walks into a zoo the onus is on him\n",
    "# --------------------------------------------------------------------------------\n",
    "# \n",
    "# Original full text: what do you call an angry german sauerkraut\n",
    "# Input (first half): what do you call an a\n",
    "# Generated continuation: what do you call an aikido fighter with no legs a kendo fighter\n",
    "# --------------------------------------------------------------------------------\n",
    "# \n",
    "# Original full text: there are churches for christians synagogues for jews and 911 for muslims\n",
    "# Input (first half): there are churches for christians sy\n",
    "# Generated continuation: there are churches for christians syrianism and communism\n",
    "--------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00f8fe67833c4636a1e43f0d27a7f498": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "01353a05a3164a2992c39b3647598c67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "017a6c666f9c442484b548f2c9cb3994": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02e069c5773d4ccab4bb042d7cd8056b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_152592c69b9e4753a6a5b2237ac027cd",
      "placeholder": "​",
      "style": "IPY_MODEL_b559cf135bdf41de81c64ae766f05470",
      "value": "Saving the dataset (1/1 shards): 100%"
     }
    },
    "0550acd8b44646d98b504aa0f8c3e1be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4ab4600818d4d7793cf563e52092307",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5daadcd9badd427cacb2a4e69bb49fa7",
      "value": 1355256
     }
    },
    "086e2f292b924444b043e07665c3cf8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09ead9e124fe447eb0224f45bbdb8fd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf01b7033a8e4183877e36fd336520cd",
      "placeholder": "​",
      "style": "IPY_MODEL_660f718dc4e74ac69e05f6894053d633",
      "value": " 20679/20679 [00:00&lt;00:00, 486867.66 examples/s]"
     }
    },
    "0a143b93e2b745d180d1821a7c8e5931": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0aa1e46e98694d19bee4aeab5c03e100": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d5973f3aa284b6eb2c0699d20c618e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f85c323115a496791bd283d27e983f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b05a0f06703433a8632989c93156114",
      "placeholder": "​",
      "style": "IPY_MODEL_557df207d71a47d4a87b6ba3b589b260",
      "value": " 665/665 [00:00&lt;00:00, 23.9kB/s]"
     }
    },
    "12a5df5d3c6f4295815e3e577deb7891": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d72c36ef7612498590c367d430a8de75",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bf640e3127684bc8bdb654fd7351523d",
      "value": 1042301
     }
    },
    "13a3203259f341bb8426e6c02522614b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "152592c69b9e4753a6a5b2237ac027cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17033bbc15d44379a31f7331ed961249": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b905f46ae7d94685adea97e1885522f4",
      "max": 165432,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_570b947632d14a978bc90f19d1f44419",
      "value": 165432
     }
    },
    "17b538d81a4442b1b96254e57794f2ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c0125c7a6f24091ac16663c14eae9df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f32c78a591df42ecbe996d6279b036cf",
      "placeholder": "​",
      "style": "IPY_MODEL_2206c2ce8d04467884c32e8af4c212c8",
      "value": "Saving the dataset (1/1 shards): 100%"
     }
    },
    "1c4a3c5b89b84a81b504d6feac354f03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_641f21cb097b4e65a96362ee51fefbcc",
      "placeholder": "​",
      "style": "IPY_MODEL_276ad66d754c43aa9ceec156d20c0572",
      "value": "Filter: 100%"
     }
    },
    "1eb82d14fbe744639707a6c2c8f28ab5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1ec3b03399814ea584752c6600c5149b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ed01b57d9b04e6297e317b781cd62d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21edd04c87f84b149e1b2d1ad051e7cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2206c2ce8d04467884c32e8af4c212c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22f68528d8064708bffb94e41fd57668": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "263d3e01f87d452592503758ebbd5091": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26c74c8629724242b7760a23bff31746": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26e6969dbc1a401cabd49710d94d7947": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a3cb753d6d142ef903877dbfdaa2953",
      "placeholder": "​",
      "style": "IPY_MODEL_eac01fd9499d4029872a1614953b9eb2",
      "value": " 1.04M/1.04M [00:00&lt;00:00, 1.29MB/s]"
     }
    },
    "276ad66d754c43aa9ceec156d20c0572": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27ca0600bbba4216bd3897e3e2eee097": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa445a076bb44b62bf514a6e198dcb22",
      "placeholder": "​",
      "style": "IPY_MODEL_28b66db7b8a14d5d859ef3a3920b4a85",
      "value": " 165432/165432 [01:19&lt;00:00, 1448.59 examples/s]"
     }
    },
    "28a5b552fe914610ba581155bbc8eb97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fedf5a17149e405e8391536452af0178",
      "placeholder": "​",
      "style": "IPY_MODEL_324dbd17f67642099e7efbc6a00463cd",
      "value": " 20680/20680 [00:14&lt;00:00, 2167.97 examples/s]"
     }
    },
    "28b66db7b8a14d5d859ef3a3920b4a85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "28e5caa9ceab49e6a1f3dc7cda77ff59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a3cb753d6d142ef903877dbfdaa2953": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e92c1052e6d4674b5ba833adae960f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69fd922f66504292806f6431a554162b",
      "placeholder": "​",
      "style": "IPY_MODEL_7887b99dd3004798ac49a4b5dba395b9",
      "value": " 20680/20680 [00:00&lt;00:00, 494733.76 examples/s]"
     }
    },
    "324dbd17f67642099e7efbc6a00463cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "33cc70bcdc024c6ca27d55c7e449ccfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3430f503f594472ebfd7ba2619426bb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45b388f1c9b74df695d013dc4be73a0d",
       "IPY_MODEL_84e616a8f4764ff39f8faf5661382978",
       "IPY_MODEL_f790313008984744802841b5eecc2e49"
      ],
      "layout": "IPY_MODEL_a5c91628cdbe4a81a0ab3e6f7cd0b163"
     }
    },
    "35ecb83a003348f1ba4fce7d232d1165": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1c5828b495948558a0677409d5b57f7",
      "placeholder": "​",
      "style": "IPY_MODEL_22f68528d8064708bffb94e41fd57668",
      "value": " 456k/456k [00:00&lt;00:00, 3.00MB/s]"
     }
    },
    "37b927432f1f41bf89f811b3e03aa7ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3859171b6908414a99de4e34c60a8390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6354a01e4cd64bd98187dd40b52fbbf9",
      "max": 165432,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f50582ae895b47ba929227b318c17aac",
      "value": 165432
     }
    },
    "385c7be9229845bdaf267210f73d97a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3924490e512e4668a3a7830bfcf7e8a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cd7a2b29c20d4ecbb279d2e95c539be6",
       "IPY_MODEL_12a5df5d3c6f4295815e3e577deb7891",
       "IPY_MODEL_26e6969dbc1a401cabd49710d94d7947"
      ],
      "layout": "IPY_MODEL_c8fc1d467f954669a974b7d7ac3fd022"
     }
    },
    "39be91dfce3442ac89da65d03f24c5ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39cb09ec34274bcbaecf1533dcbd945c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bfd70a10c1744b39723d5b8606ae3a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ce64fb49f7c49c293c7296ffd4a6ced": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3dd42dac38964d0f8c5afee90b092bfd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ef8da5e1f934b2ab3f7664a9bf34414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91453694c0d843b8896220431ad302ed",
      "placeholder": "​",
      "style": "IPY_MODEL_f4d4f4b2b65f41239237d8598befcf8b",
      "value": " 165432/165432 [00:00&lt;00:00, 1416649.52 examples/s]"
     }
    },
    "3f641c22fad840369e82031761e711cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_64b4ebe1aa064e3cbb49eb38b921ddbf",
       "IPY_MODEL_0550acd8b44646d98b504aa0f8c3e1be",
       "IPY_MODEL_551e62cb053a4ba9a291fbb7bb63417b"
      ],
      "layout": "IPY_MODEL_39be91dfce3442ac89da65d03f24c5ea"
     }
    },
    "3f9d475fe4004ca6be1971a8d062b0da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fa48917b8704a3d9cec66760ed2defd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fcb253eb0c94438b37d4e418c288595": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fb90b45a7bf4ed69c78d7ab18675a97",
      "placeholder": "​",
      "style": "IPY_MODEL_e45943138887443e80b2b79db2df414c",
      "value": " 165432/165432 [00:05&lt;00:00, 24241.04 examples/s]"
     }
    },
    "4180526e5fc34722b0cd5905c2aad493": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aadb492e9fc349619ae2bf7e8a72f92e",
      "max": 20679,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5bb388f5f8ab41d8bd25c004a9283132",
      "value": 20679
     }
    },
    "444cb38acc2a4536a55656408b2ce664": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45b388f1c9b74df695d013dc4be73a0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26c74c8629724242b7760a23bff31746",
      "placeholder": "​",
      "style": "IPY_MODEL_00f8fe67833c4636a1e43f0d27a7f498",
      "value": "Tokenizing training set: 100%"
     }
    },
    "46538dc6e20046eb8bb9e8d970a7e3df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "498b9cb7b8744651af044e188cc2be2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01353a05a3164a2992c39b3647598c67",
      "max": 20679,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_541b332fea1c44efb6b3d9bdc4242acf",
      "value": 20679
     }
    },
    "4b05a0f06703433a8632989c93156114": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cd07b51e539488caf9510a370d12104": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac4289fe6faa46a39f39b5759ab3c289",
      "max": 165432,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_54da7c79f9ab48439196463163d2c666",
      "value": 165432
     }
    },
    "4fb90b45a7bf4ed69c78d7ab18675a97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50c1195a214b4249838a04006ca4babb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51baa10c6ec646598e1d141107c1c36d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "541b332fea1c44efb6b3d9bdc4242acf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "54da7c79f9ab48439196463163d2c666": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "551e62cb053a4ba9a291fbb7bb63417b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e33c346babbb49e6a880652145e43fa6",
      "placeholder": "​",
      "style": "IPY_MODEL_444cb38acc2a4536a55656408b2ce664",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 5.55MB/s]"
     }
    },
    "557df207d71a47d4a87b6ba3b589b260": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "570b947632d14a978bc90f19d1f44419": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "59e201ab43bd4b4f956fe81cddb07fe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a3a430c21904f098e7bd7f8310bf5db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bb388f5f8ab41d8bd25c004a9283132": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5d3a4e62ba7f4e2bbfdc4cf0710ed047": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5daadcd9badd427cacb2a4e69bb49fa7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "610e05ef4f204b6bb8c30b2969c99f93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6110cf51bf754339b59fdde197ae56c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62cb9149543e4bd88b55ddd4403cc669": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb08227717624154b18a6711462d5f6f",
      "max": 20679,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_33cc70bcdc024c6ca27d55c7e449ccfd",
      "value": 20679
     }
    },
    "6354a01e4cd64bd98187dd40b52fbbf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "641f21cb097b4e65a96362ee51fefbcc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6461dadd450c4e67b61126355d4805c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "64b4ebe1aa064e3cbb49eb38b921ddbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b811bfcf177741b29377f0ed0266774f",
      "placeholder": "​",
      "style": "IPY_MODEL_e417ff1bca1d40c98d561a5182b90d2a",
      "value": "tokenizer.json: 100%"
     }
    },
    "660f718dc4e74ac69e05f6894053d633": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69fd922f66504292806f6431a554162b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6abbf7a521d24e9193dd693406bf1a0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ad0aad4fa1f4a1981e6025b9f4bc3a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cf54586db8f547cba952f3bc1968d79b",
       "IPY_MODEL_f2163826aa314ba0882d4bba90e5ddb2",
       "IPY_MODEL_35ecb83a003348f1ba4fce7d232d1165"
      ],
      "layout": "IPY_MODEL_b60120e0c8034c94a277a2e63009348e"
     }
    },
    "6d81495d405c47ec9aaf3a01a1170498": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_80cd95b71fae42f6a02bf547e96ea1e5",
       "IPY_MODEL_498b9cb7b8744651af044e188cc2be2f",
       "IPY_MODEL_fe41e1ab095648d8aa4962d143e30131"
      ],
      "layout": "IPY_MODEL_0d5973f3aa284b6eb2c0699d20c618e8"
     }
    },
    "6f4357cd4fab4658a430e3ebec9ce75a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f7c180b6d7d4ae0b5eadbcf0e2235c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c0125c7a6f24091ac16663c14eae9df",
       "IPY_MODEL_4180526e5fc34722b0cd5905c2aad493",
       "IPY_MODEL_9afd75558a534a79a3135a431cf6025f"
      ],
      "layout": "IPY_MODEL_dec6919017234e668988e6f17cda38e0"
     }
    },
    "6faaf2dd2db440c5a0ffb1e1cbed583d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72c06b7fcf98462e9ab351a4fee9fd55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7431529224344ed5af4a83b4f2c5cdf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8fc762e24bbd4e2d89d69ec0c0b3a2fd",
       "IPY_MODEL_3859171b6908414a99de4e34c60a8390",
       "IPY_MODEL_3ef8da5e1f934b2ab3f7664a9bf34414"
      ],
      "layout": "IPY_MODEL_d1bfec2ab87f48a9b9a310421a9cab42"
     }
    },
    "76ffa237f97d4d0fb40750c363dd2507": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7887b99dd3004798ac49a4b5dba395b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b7810cb778f41cfa700f5eda2bf0f31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb487b98b8074426b58d753a99238d72",
      "max": 20680,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3ce64fb49f7c49c293c7296ffd4a6ced",
      "value": 20680
     }
    },
    "7bfc727a31a74f6580652ca95f5aee3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9c59ee08d7be4034924b00d95b02f0ea",
       "IPY_MODEL_b3fdde54e9d84b30bf89f53429ffc301",
       "IPY_MODEL_97a84a1534b142969e7a24df02632695"
      ],
      "layout": "IPY_MODEL_50c1195a214b4249838a04006ca4babb"
     }
    },
    "7e05f14e88524dd18a950d07a083b4ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80cd95b71fae42f6a02bf547e96ea1e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ed01b57d9b04e6297e317b781cd62d8",
      "placeholder": "​",
      "style": "IPY_MODEL_eff94198d04d43b9b08781fc5a26d6cc",
      "value": "Tokenizing validation set: 100%"
     }
    },
    "814f15358a4541d5998116d24f9c0074": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "848bdcd923f248cd9f94c1a48a348ee0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84e616a8f4764ff39f8faf5661382978": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ec3b03399814ea584752c6600c5149b",
      "max": 165432,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3bfd70a10c1744b39723d5b8606ae3a2",
      "value": 165432
     }
    },
    "8fc762e24bbd4e2d89d69ec0c0b3a2fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6abbf7a521d24e9193dd693406bf1a0c",
      "placeholder": "​",
      "style": "IPY_MODEL_e7fdb4efac7c40efac734613f100297a",
      "value": "Saving the dataset (1/1 shards): 100%"
     }
    },
    "90055d2ec65b45c08d92353020a440e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91453694c0d843b8896220431ad302ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97a84a1534b142969e7a24df02632695": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13a3203259f341bb8426e6c02522614b",
      "placeholder": "​",
      "style": "IPY_MODEL_ebe0dc4364664e72be5798fab8e5aba8",
      "value": " 20680/20680 [00:08&lt;00:00, 2969.63 examples/s]"
     }
    },
    "97cf479f25b74af7a3c30d31538113ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c7ea1b96cd7b45459f8eb32d1b4600c9",
       "IPY_MODEL_62cb9149543e4bd88b55ddd4403cc669",
       "IPY_MODEL_09ead9e124fe447eb0224f45bbdb8fd9"
      ],
      "layout": "IPY_MODEL_6f4357cd4fab4658a430e3ebec9ce75a"
     }
    },
    "9a2d0832d729475e9f0d1219d7d8c7fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9afd75558a534a79a3135a431cf6025f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_017a6c666f9c442484b548f2c9cb3994",
      "placeholder": "​",
      "style": "IPY_MODEL_a4bc3fcefed847a6bb75ce888bc300f3",
      "value": " 20679/20679 [00:00&lt;00:00, 29459.57 examples/s]"
     }
    },
    "9c59ee08d7be4034924b00d95b02f0ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_848bdcd923f248cd9f94c1a48a348ee0",
      "placeholder": "​",
      "style": "IPY_MODEL_814f15358a4541d5998116d24f9c0074",
      "value": "Tokenizing test set: 100%"
     }
    },
    "9c6e5d0fc0134094974ebfefbb03edf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c9396faccd44a63a8c89467b9a0371d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a09d5049e7804c88b7fe9058663a3955": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e88261367ddd4824b552f4a315b2faa4",
      "placeholder": "​",
      "style": "IPY_MODEL_263d3e01f87d452592503758ebbd5091",
      "value": " 20680/20680 [00:05&lt;00:00, 2863.54 examples/s]"
     }
    },
    "a4bc3fcefed847a6bb75ce888bc300f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5c5a3eaaf334e1089ea713b6e8a04f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ec4f9abc951e42a191291a5e87d35b9b",
       "IPY_MODEL_e9d6b496578e436b98be6bdc98ef54ab",
       "IPY_MODEL_b2c0f3e320b84a138ecc9d3038c39ff8"
      ],
      "layout": "IPY_MODEL_e85456980bbb4b4fa490d0c61ecd3732"
     }
    },
    "a5c91628cdbe4a81a0ab3e6f7cd0b163": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa445a076bb44b62bf514a6e198dcb22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aadb492e9fc349619ae2bf7e8a72f92e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac4289fe6faa46a39f39b5759ab3c289": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad77682b6279417eb73b5af7af17cc55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aeaf7bb7ceca4bafbcfb6c7d03d1a70c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b06128a5f4e449329b52bc57d19def0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2c0f3e320b84a138ecc9d3038c39ff8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a143b93e2b745d180d1821a7c8e5931",
      "placeholder": "​",
      "style": "IPY_MODEL_c9ebfab4d73c47fc8065856ac6c86669",
      "value": " 26.0/26.0 [00:00&lt;00:00, 532B/s]"
     }
    },
    "b2e5ced552424286a48c46f831181568": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbac39be46e941629dc34fc9082e8e6a",
      "placeholder": "​",
      "style": "IPY_MODEL_9c9396faccd44a63a8c89467b9a0371d",
      "value": "Saving the dataset (1/1 shards): 100%"
     }
    },
    "b3fdde54e9d84b30bf89f53429ffc301": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37b927432f1f41bf89f811b3e03aa7ce",
      "max": 20680,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c8b93cd1a1d1469091e97646b4ae2839",
      "value": 20680
     }
    },
    "b559cf135bdf41de81c64ae766f05470": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5c047321eec42c9ac1c300d00ed3a9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b60120e0c8034c94a277a2e63009348e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6473331903a40c5aadc88b16fa7bdb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b811bfcf177741b29377f0ed0266774f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b905f46ae7d94685adea97e1885522f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "baf492efc3434acd8c26d4e86e04f7cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb3c6ba85d8842f790b3b84c6b1400e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6110cf51bf754339b59fdde197ae56c5",
      "placeholder": "​",
      "style": "IPY_MODEL_9c6e5d0fc0134094974ebfefbb03edf1",
      "value": "config.json: 100%"
     }
    },
    "bd993f19a38d499ba5727dc854af0a24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf640e3127684bc8bdb654fd7351523d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c1c5828b495948558a0677409d5b57f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c31a0a71eb374ed7bf4deb14d8f0b6fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bb3c6ba85d8842f790b3b84c6b1400e8",
       "IPY_MODEL_e3c511d78ef04165a8cdbd70a7aa978e",
       "IPY_MODEL_0f85c323115a496791bd283d27e983f5"
      ],
      "layout": "IPY_MODEL_6faaf2dd2db440c5a0ffb1e1cbed583d"
     }
    },
    "c7667a4314df4835b71d26a24f60cc3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7ea1b96cd7b45459f8eb32d1b4600c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_086e2f292b924444b043e07665c3cf8a",
      "placeholder": "​",
      "style": "IPY_MODEL_5d3a4e62ba7f4e2bbfdc4cf0710ed047",
      "value": "Saving the dataset (1/1 shards): 100%"
     }
    },
    "c8620d3d2a6d48b0a06a91b4a7289ccf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b2e5ced552424286a48c46f831181568",
       "IPY_MODEL_ee6e93b459b44363beffa86855d183ed",
       "IPY_MODEL_2e92c1052e6d4674b5ba833adae960f4"
      ],
      "layout": "IPY_MODEL_3fa48917b8704a3d9cec66760ed2defd"
     }
    },
    "c8b93cd1a1d1469091e97646b4ae2839": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c8fc1d467f954669a974b7d7ac3fd022": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9959d700f28475e86b9b670ed9e7367": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d340cf5239c344e598c2ccac65130f1a",
      "max": 20680,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eb73994b0a8a4106af1fe66872e6919d",
      "value": 20680
     }
    },
    "c9ebfab4d73c47fc8065856ac6c86669": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "caf4448bbfbc426c9d503d7423a7a603": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb08227717624154b18a6711462d5f6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd7a2b29c20d4ecbb279d2e95c539be6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21edd04c87f84b149e1b2d1ad051e7cd",
      "placeholder": "​",
      "style": "IPY_MODEL_f76f2f6e504c46a4a0143cf5b3c14c75",
      "value": "vocab.json: 100%"
     }
    },
    "cf01b7033a8e4183877e36fd336520cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf4ec13b65ef4973b29d678223863328": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_baf492efc3434acd8c26d4e86e04f7cf",
      "placeholder": "​",
      "style": "IPY_MODEL_aeaf7bb7ceca4bafbcfb6c7d03d1a70c",
      "value": "Filter: 100%"
     }
    },
    "cf54586db8f547cba952f3bc1968d79b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76ffa237f97d4d0fb40750c363dd2507",
      "placeholder": "​",
      "style": "IPY_MODEL_ad77682b6279417eb73b5af7af17cc55",
      "value": "merges.txt: 100%"
     }
    },
    "d164b459c4ad495487deba8e85c35ae9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_610e05ef4f204b6bb8c30b2969c99f93",
      "placeholder": "​",
      "style": "IPY_MODEL_b5c047321eec42c9ac1c300d00ed3a9c",
      "value": "Filter: 100%"
     }
    },
    "d1bfec2ab87f48a9b9a310421a9cab42": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d340cf5239c344e598c2ccac65130f1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5ab1d724e664279841e0567b6cdd57c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ec6f784dd366446585ef5ad4800c9067",
       "IPY_MODEL_7b7810cb778f41cfa700f5eda2bf0f31",
       "IPY_MODEL_a09d5049e7804c88b7fe9058663a3955"
      ],
      "layout": "IPY_MODEL_caf4448bbfbc426c9d503d7423a7a603"
     }
    },
    "d72c36ef7612498590c367d430a8de75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d738a30a593c49ffa3f95505b6b3efe2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da37b9273aaa4ee2ad46e9c201cf484d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dbac39be46e941629dc34fc9082e8e6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd7dda77623c4e35bd7241eb9476e377": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cf4ec13b65ef4973b29d678223863328",
       "IPY_MODEL_e2ee3d1677f542e48963694fd40196ce",
       "IPY_MODEL_e1285c6c241542ee973371f266435cb1"
      ],
      "layout": "IPY_MODEL_3dd42dac38964d0f8c5afee90b092bfd"
     }
    },
    "dec6919017234e668988e6f17cda38e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1285c6c241542ee973371f266435cb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6b5119e482844168c4d4fda532e78de",
      "placeholder": "​",
      "style": "IPY_MODEL_b6473331903a40c5aadc88b16fa7bdb3",
      "value": " 20679/20679 [00:08&lt;00:00, 2470.77 examples/s]"
     }
    },
    "e14c4f16cbeb4098aa4f157aaf9a3604": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d164b459c4ad495487deba8e85c35ae9",
       "IPY_MODEL_c9959d700f28475e86b9b670ed9e7367",
       "IPY_MODEL_28a5b552fe914610ba581155bbc8eb97"
      ],
      "layout": "IPY_MODEL_c7667a4314df4835b71d26a24f60cc3a"
     }
    },
    "e2ee3d1677f542e48963694fd40196ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0aa1e46e98694d19bee4aeab5c03e100",
      "max": 20679,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1eb82d14fbe744639707a6c2c8f28ab5",
      "value": 20679
     }
    },
    "e301653980394cebaa783623062c176d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c4a3c5b89b84a81b504d6feac354f03",
       "IPY_MODEL_4cd07b51e539488caf9510a370d12104",
       "IPY_MODEL_27ca0600bbba4216bd3897e3e2eee097"
      ],
      "layout": "IPY_MODEL_385c7be9229845bdaf267210f73d97a7"
     }
    },
    "e33c346babbb49e6a880652145e43fa6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3c511d78ef04165a8cdbd70a7aa978e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e05f14e88524dd18a950d07a083b4ff",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_da37b9273aaa4ee2ad46e9c201cf484d",
      "value": 665
     }
    },
    "e417ff1bca1d40c98d561a5182b90d2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e45943138887443e80b2b79db2df414c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e7974c72742e49d58e90351630791351": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_02e069c5773d4ccab4bb042d7cd8056b",
       "IPY_MODEL_17033bbc15d44379a31f7331ed961249",
       "IPY_MODEL_3fcb253eb0c94438b37d4e418c288595"
      ],
      "layout": "IPY_MODEL_28e5caa9ceab49e6a1f3dc7cda77ff59"
     }
    },
    "e7fdb4efac7c40efac734613f100297a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e85456980bbb4b4fa490d0c61ecd3732": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e88261367ddd4824b552f4a315b2faa4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9d6b496578e436b98be6bdc98ef54ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d738a30a593c49ffa3f95505b6b3efe2",
      "max": 26,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9a2d0832d729475e9f0d1219d7d8c7fb",
      "value": 26
     }
    },
    "eac01fd9499d4029872a1614953b9eb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb73994b0a8a4106af1fe66872e6919d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ebe0dc4364664e72be5798fab8e5aba8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec4f9abc951e42a191291a5e87d35b9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39cb09ec34274bcbaecf1533dcbd945c",
      "placeholder": "​",
      "style": "IPY_MODEL_72c06b7fcf98462e9ab351a4fee9fd55",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "ec6f784dd366446585ef5ad4800c9067": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17b538d81a4442b1b96254e57794f2ba",
      "placeholder": "​",
      "style": "IPY_MODEL_59e201ab43bd4b4f956fe81cddb07fe9",
      "value": "Saving the dataset (1/1 shards): 100%"
     }
    },
    "ee6e93b459b44363beffa86855d183ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f9d475fe4004ca6be1971a8d062b0da",
      "max": 20680,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46538dc6e20046eb8bb9e8d970a7e3df",
      "value": 20680
     }
    },
    "eff94198d04d43b9b08781fc5a26d6cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2163826aa314ba0882d4bba90e5ddb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a3a430c21904f098e7bd7f8310bf5db",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_51baa10c6ec646598e1d141107c1c36d",
      "value": 456318
     }
    },
    "f32c78a591df42ecbe996d6279b036cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4ab4600818d4d7793cf563e52092307": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4d4f4b2b65f41239237d8598befcf8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f50582ae895b47ba929227b318c17aac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f6b5119e482844168c4d4fda532e78de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f76f2f6e504c46a4a0143cf5b3c14c75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f790313008984744802841b5eecc2e49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b06128a5f4e449329b52bc57d19def0d",
      "placeholder": "​",
      "style": "IPY_MODEL_6461dadd450c4e67b61126355d4805c3",
      "value": " 165432/165432 [01:28&lt;00:00, 2717.58 examples/s]"
     }
    },
    "fb487b98b8074426b58d753a99238d72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe41e1ab095648d8aa4962d143e30131": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90055d2ec65b45c08d92353020a440e6",
      "placeholder": "​",
      "style": "IPY_MODEL_bd993f19a38d499ba5727dc854af0a24",
      "value": " 20679/20679 [00:06&lt;00:00, 2700.71 examples/s]"
     }
    },
    "fedf5a17149e405e8391536452af0178": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
